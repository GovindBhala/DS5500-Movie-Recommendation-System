{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "- Sampling ratings by # of users\n",
    "\n",
    "- Users filtered: the users who have rated minimum of 20 movies\n",
    "\n",
    "- Filtering movies with at least 50 ratings \n",
    "\n",
    "- Suprise Library\n",
    "    \n",
    "       - Memory Based\n",
    "        \n",
    "       - Model Based\n",
    "      \n",
    "- Comparison between different algorithms: \n",
    "        \n",
    "       - 1000 users\n",
    "        \n",
    "       - cv =5\n",
    "        \n",
    "       - metric: rmse\n",
    "\n",
    "       - selected the model with the least test_rmse\n",
    "       \n",
    "- Evaluations: separate notebook\n",
    "    \n",
    "        - Precision/Recall @K k =5\n",
    "        \n",
    "        - Personalization Score: 5fold\n",
    "        \n",
    "        - Personal Diversity: top 10 movies\n",
    "        \n",
    "        - General Diversity: # of users = 20 , top 10 recommendation\n",
    "        \n",
    "        - Average of average ratings: # of users = 20 , top 10 recommendation\n",
    "\n",
    "\n",
    "       \n",
    "- Top two models compared:\n",
    "        \n",
    "        - SVDpp()\n",
    "        \n",
    "        - KNNBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Personalization | Precision@10 | Recall@10 | Personal diversity | Global diversity | Average rating\n",
    "| --- | --- | --- | --- | --- | --- | --- \n",
    "| SVDpp | 0.79 | 0.87 | 0.26 | 0.36 | 1495.15 | 4.07\n",
    "| KNNBaseline | 0.8 | 0.84 | 0.27 | 0.42 | 86.2 | 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Model Selected: KNNBaseline \n",
    "\n",
    "    - Build train dataset using users_ratings['userId','movieId','rating' ]\n",
    "    \n",
    "    - Model is trained on complete data(user-item)\n",
    "    \n",
    "    - Builds test set using build_anti_testset: it created all the user-item combinations\n",
    "      not present in the actuat dataset(trainset). This returns a list uid\tiid\tr_ui\t\n",
    "      here r_ui the global mean of all ratings as here user is known, item is known only\n",
    "      the r_ui is known.\n",
    "      \n",
    "    - Predictions: an estimated rating is predicted for the user-item combination in the test set.\n",
    "    \n",
    "    - Recommendation:\n",
    "        \n",
    "        -  create user_profile: filter all the user-item ratings based on the user_id from the testset\n",
    "        \n",
    "        -  recommend top_n movies to the user\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import operator\n",
    "import scipy.spatial.distance as distance\n",
    "from sklearn import metrics \n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import fastparquet\n",
    "from scipy.sparse import csr_matrix\n",
    "from surprise import SVD,Dataset,Reader\n",
    "from collections import defaultdict\n",
    "from surprise.model_selection import cross_validate,KFold\n",
    "from surprise import SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('processed_files/processed_df.parq')\n",
    "ratings = pd.read_parquet('processed_files/ratings_sample_useradd.parq')\n",
    "ratings = ratings.reset_index()\n",
    "movies_raitings = pd.read_parquet('processed_files/movies_ratings.parq')\n",
    "movies_raitings = movies_raitings.rename(columns={\"avg\": \"Average_Ratings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_files/sparse_metadata', \"rb\") as f:\n",
    "    cols = pickle.load(f)\n",
    "    movieIds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering movies rated at least by 50 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of movies at least rated by 50 users: 11840\n"
     ]
    }
   ],
   "source": [
    "filtered_movies = movies_raitings[movies_raitings['cnt']>50].movieId.values\n",
    "moviesfilters = ratings[ratings.movieId.isin(filtered_movies)]\n",
    "\n",
    "print(f' Number of movies at least rated by 50 users: {len(filtered_movies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating users list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of users who rated at least 20 movies: 40634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     2,      8,     14, ..., 162523, 162524, 162534])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_list = ratings.groupby('userId')['userId'].count().reset_index(name=\"rating_count\")\n",
    "print(f' Number of users who rated at least 20 movies: {len(users_list)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model trained using n_users ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ratings for 1000 is 150062\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "n_users = 1000\n",
    "users_list = set(users_list.userId.unique())\n",
    "random_users = random.sample(users_list, n_users)\n",
    "users_ratings = moviesfilters[moviesfilters.userId.isin(random_users)]\n",
    "print(f' ratings for {n_users} is {len(users_ratings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering movie data for getting movie metdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_filters = np.unique(users_ratings.movieId.values)\n",
    "movie_rating = movies_raitings[movies_raitings.movieId.isin(movies_filters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ratings = users_ratings[['userId','movieId','rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below section is to train the model. Model is currently trained and saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting the min max rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rat = users_ratings.rating.min()\n",
    "max_rat = users_ratings.rating.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# specify the range of rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(min_rat,max_rat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading users_ratings using load_from_df for model comparison: \n",
    "The columns must correspond to user id, item id and ratings (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(users_ratings, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models compared \n",
    "\n",
    "Models are compared using 1000 users ratings data\n",
    "\n",
    "- SVD()\n",
    "\n",
    "- SVDpp()\n",
    "\n",
    "- SlopeOne() \n",
    "\n",
    "- NMF()\n",
    "\n",
    "- NormalPredictor()\n",
    "\n",
    "- KNNBaseline()\n",
    "\n",
    "- KNNBasic()\n",
    "\n",
    "- KNNWithMeans()\n",
    "\n",
    "- KNNWithZScore()\n",
    "\n",
    "- BaselineOnly()\n",
    "\n",
    "- CoClustering()\n",
    "\n",
    "The below block has been executed once, I have commented it now. The results are stored and can be read from the parq file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "results_test_df = []\n",
    "# Iterate over all surprise algorithms\n",
    "\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation cv =5\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append into results_test_df\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    results_test_df.append(tmp)\n",
    "    \n",
    "pd.DataFrame(results_test_df).set_index('Algorithm').sort_values('test_rmse')  \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df_test_score contains the comparison statistics of the above models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_score = pd.DataFrame(results_test_df).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the comparison results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_score.to_parquet('test_rmse_score_comparison.parq', engine = 'fastparquet', compression = 'GZIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting the model with least rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.870838</td>\n",
       "      <td>750.548304</td>\n",
       "      <td>8.109057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.878081</td>\n",
       "      <td>2.111808</td>\n",
       "      <td>11.520009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>0.878819</td>\n",
       "      <td>0.696858</td>\n",
       "      <td>0.565961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.884845</td>\n",
       "      <td>6.801081</td>\n",
       "      <td>0.555114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.893763</td>\n",
       "      <td>1.255122</td>\n",
       "      <td>7.649508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.895202</td>\n",
       "      <td>1.205560</td>\n",
       "      <td>8.984960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.895398</td>\n",
       "      <td>247.660159</td>\n",
       "      <td>18.841247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>0.920075</td>\n",
       "      <td>27.935698</td>\n",
       "      <td>1.137187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>0.939221</td>\n",
       "      <td>4.204486</td>\n",
       "      <td>0.627891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.943295</td>\n",
       "      <td>1.103818</td>\n",
       "      <td>8.500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.430397</td>\n",
       "      <td>0.537468</td>\n",
       "      <td>1.041328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse    fit_time  test_time\n",
       "Algorithm                                        \n",
       "SVDpp             0.870838  750.548304   8.109057\n",
       "KNNBaseline       0.878081    2.111808  11.520009\n",
       "BaselineOnly      0.878819    0.696858   0.565961\n",
       "SVD               0.884845    6.801081   0.555114\n",
       "KNNWithZScore     0.893763    1.255122   7.649508\n",
       "KNNWithMeans      0.895202    1.205560   8.984960\n",
       "SlopeOne          0.895398  247.660159  18.841247\n",
       "NMF               0.920075   27.935698   1.137187\n",
       "CoClustering      0.939221    4.204486   0.627891\n",
       "KNNBasic          0.943295    1.103818   8.500007\n",
       "NormalPredictor   1.430397    0.537468   1.041328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_score = pd.read_parquet('processed_files/test_rmse_score_comparison.parq')\n",
    "df_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the similarity option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the similarity option \n",
    "\n",
    "item_based = {'name': 'cosine',\n",
    "               'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "\n",
    "user_based = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0  # no shrinkage\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.862782</td>\n",
       "      <td>0.656062</td>\n",
       "      <td>1.125165</td>\n",
       "      <td>3.005531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.872462</td>\n",
       "      <td>0.667737</td>\n",
       "      <td>12.736901</td>\n",
       "      <td>9.376762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_rmse  test_mae   fit_time  test_time\n",
       "Algorithm                                             \n",
       "KNNBaseline   0.862782  0.656062   1.125165   3.005531\n",
       "KNNBaseline   0.872462  0.667737  12.736901   9.376762"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_comp = []\n",
    "\n",
    "for algorithm in [KNNBaseline(sim_options=user_based), KNNBaseline(sim_options=item_based)]:\n",
    "    # Perform cross validation cv =5\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE','MAE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append into results_test_df\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    results_comp.append(tmp)\n",
    "    \n",
    "pd.DataFrame(results_comp).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model KNNBaseline\n",
    "\n",
    "- User-User \n",
    "- using pearson_baseline\n",
    "\n",
    "### The model has beed commented and dumped into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "user_based = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0  # no shrinkage\n",
    "               }\n",
    "\n",
    "KNN = KNNBaseline(sim_options=user_based)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a train set using the complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit the trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7fe4a2a0e310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'processed_files/KNNBaseline_model_pearson_baseline.pkl'\n",
    "#pickle.dump(KNN, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the model from the dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'processed_files/KNNBaseline_model_pearson_baseline.pkl'\n",
    "#KNNBas = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation:\n",
    "\n",
    "\n",
    "1) testset : Create user Item combination that is not available in the train set.\n",
    "\n",
    "2) predictions: predict ratings for the user-item in the test set\n",
    "\n",
    "3) Save all the predictions data into predicted_ratings\n",
    "\n",
    "All the predictions are saved into the predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = KNNBas.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_ratings = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_ratings.to_parquet('Predictions/KNN_predictions_df.parq', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation starts here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = pd.read_parquet('Predictions/KNN_predictions_df.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>3.055887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>3.112601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>3.104419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>3.766334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>21</td>\n",
       "      <td>3.148158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57627410</th>\n",
       "      <td>162514</td>\n",
       "      <td>30996</td>\n",
       "      <td>3.448362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57627411</th>\n",
       "      <td>162514</td>\n",
       "      <td>47330</td>\n",
       "      <td>3.448362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57627412</th>\n",
       "      <td>162514</td>\n",
       "      <td>160684</td>\n",
       "      <td>3.340844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57627413</th>\n",
       "      <td>162514</td>\n",
       "      <td>65588</td>\n",
       "      <td>3.469857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57627414</th>\n",
       "      <td>162514</td>\n",
       "      <td>7457</td>\n",
       "      <td>3.355044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57627415 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  prediction\n",
       "0             75        2    3.055887\n",
       "1             75        3    3.112601\n",
       "2             75        7    3.104419\n",
       "3             75       11    3.766334\n",
       "4             75       21    3.148158\n",
       "...          ...      ...         ...\n",
       "57627410  162514    30996    3.448362\n",
       "57627411  162514    47330    3.448362\n",
       "57627412  162514   160684    3.340844\n",
       "57627413  162514    65588    3.469857\n",
       "57627414  162514     7457    3.355044\n",
       "\n",
       "[57627415 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[['uid','iid','est']].rename(columns = {'est':'prediction', 'uid':'userId', 'iid':'movieId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filtering_model(userId,movie_rating,predicted_ratings,top_n):\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions recommends top_n movies to the end user\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    single_user = predicted_ratings[predicted_ratings['uid']==userId]\n",
    "    top_nmovies = single_user.sort_values(by = ['est'] , ascending = False)[:top_n]['iid']\n",
    "    \n",
    "    recommendations = pd.merge(top_nmovies,movie_rating, how='left', left_on='iid',right_on='movieId')\n",
    "    \n",
    "    \n",
    "    recommendations = recommendations[['movieId', 'title_eng', 'Average_Ratings', 'cnt']]\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top_n recommendation for a user\n",
    "\n",
    "1) Give userId\n",
    "\n",
    "2) top_n: # of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_list = set(users_ratings.userId.values)\n",
    "random_userId = random.sample(user_id_list, 1)\n",
    "top_n = 10\n",
    "recommendations = collaborative_filtering_model(random_userId[0],movie_rating,predicted_ratings,top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
