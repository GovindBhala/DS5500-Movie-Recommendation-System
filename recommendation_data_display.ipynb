{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for recommendations display \n",
    "- Merge movie data with all meta-data for display + filtering\n",
    "- Calculate weighted average of ratings\n",
    "    - Primary sort key for non user filter recommendations\n",
    "    - Secondary sort key for same cosine similarity in user-item and item-item recommendations\n",
    "- Downcased versions of variables that user may input (actor, diretor for filters and title for item-item)\n",
    "- Create new variables: round average ratings to 1 decimal, separated delimited language list, length of tags lists\n",
    "- Order and rename columns for display - include non-display columns that are needed for setup at the end\n",
    "- Save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import operator\n",
    "import fastparquet\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    ### processed data from recommendation data exploration.ipynb\n",
    "    # movie attributes\n",
    "    df = pd.read_parquet('processed_files/movies_processed.parq')\n",
    "    df = df.drop(columns = ['director', 'actors', 'country', 'description', 'text',\n",
    "                            'text_top5', 'desc_top5', 'tag_cleaned', 'tags_rel', 'tag_top5'])\n",
    "    # strip year out of title. Match on ( followed by number. () sometimes valid part of title\n",
    "    df['title'] = df.title_eng.apply(lambda row: re.split('\\\\([0-9]', row)[0].strip())    \n",
    "    \n",
    "    # number of and average ratings by movie\n",
    "    movie_ratings = pd.read_parquet('processed_files/movies_ratings.parq')\n",
    "\n",
    "    ### data to get additional attributes for display\n",
    "    links = pd.read_csv('data/ml-25m/links.csv')\n",
    "    imdb_movies = pd.read_csv('data/imdb/IMDb movies.csv')\n",
    "\n",
    "    return df, movie_ratings, links, imdb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Average Ratings\n",
    "- \\# of ratings * average rating    \n",
    "    - If just use average rating, many movies only reviewed once or twice. Want highly rated, frequently watched movies   \n",
    "    - This does weight poorly rated, but frequently watched movies higher place than well rated, infrequently movies\n",
    "- Uses:\n",
    "    - Primary sort key for non user filter recommendations\n",
    "    - Secondary sort key for same cosine similarity in user-item and item-item recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def weighted_avg(movie_ratings, df):\n",
    "    # calculate weighted average\n",
    "    movie_ratings['weighted_avg'] = movie_ratings.avg * movie_ratings.cnt\n",
    "\n",
    "    # merge with df with movie attributes\n",
    "    # LEFT merge so keep movies with no ratings (weighted avg = 0) -- can still recommend if fit specific filters\n",
    "    df = pd.merge(df, movie_ratings[['movieId', 'weighted_avg', 'cnt', 'avg']], on = 'movieId', how = 'left')\n",
    "\n",
    "    # replace nulls to 0 \n",
    "    # NOT avg: should display missing if missing\n",
    "    for var in ['weighted_avg', 'cnt']:\n",
    "        df[var] = np.where(df[var].isnull(), 0, df[var])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in additional IMDB attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_merge(imdb_movies, links, df):\n",
    "    # standardize IMDB IDs\n",
    "    imdb_movies['imdbId'] = imdb_movies.imdb_title_id.str.split('tt').str[1]\n",
    "    imdb_movies.imdbId = pd.to_numeric(imdb_movies.imdbId)\n",
    "    \n",
    "    x = len(df)\n",
    "    # merge links to identify IMDB movies\n",
    "    df = pd.merge(df, links[['movieId', 'imdbId']], on = 'movieId')\n",
    "    # merge specific IMDB attributes\n",
    "    df = pd.merge(df, imdb_movies[['imdbId', 'description', 'language', 'duration', 'production_company']])\n",
    "    assert x == len(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcase User Input Variables so can match user input non case-sensitive  \n",
    "Keep non-downcased version for displaying   \n",
    "Filters:\n",
    "- Actors\n",
    "- Directors     \n",
    "    \n",
    "Item-Item input: \n",
    "- Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcasing(df):\n",
    "    df['actors_downcased'] = df.actors_lst.apply(lambda row: [i.lower() for i in row])\n",
    "    df['directors_downcased'] = df.director_lst.apply(lambda row: [i.lower() for i in row])\n",
    "    df['title_downcased'] = df.title.apply(lambda row: row.lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new variables\n",
    "- Round average rating to 1 decimal\n",
    "- Language list delimited separate\n",
    "- Number of tags\n",
    "    - For item-item recommendations, need to know if user selected movie has any tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vars(df):\n",
    "    # round ratings for display (1 decimal)\n",
    "    df.loc[:,'avg'] = df.loc[:,'avg'].round(1)\n",
    "    df['avg'] = df['avg'].apply(str)\n",
    "    \n",
    "    # language to list\n",
    "    for var in ['language']:\n",
    "        df[var + '_lst'] = df[var].str.split(', ')\n",
    "        df[var + '_lst'] = df[var + '_lst'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        \n",
    "    # number of tags\n",
    "    df.tag = df.tag.apply(lambda row: [i for i in row if i != ''])\n",
    "    df['tag_num'] = df.tag.apply(lambda row: len(row))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrame for Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataframe(df):\n",
    "    \n",
    "    df_display = df.copy()\n",
    "    \n",
    "    # drop columns\n",
    "    df_display = df_display.drop(columns = ['imdbId', 'language'])\n",
    "\n",
    "    # rename + reorder columns\n",
    "    df_display.columns = ['movieId', 'title_year', 'Year', 'Production Company', 'decade', 'Genres', 'Director(s)',\n",
    "                          'Actors', 'Filming Countries', 'Tags', 'Title', 'weighted_avg', 'Number of Ratings', 'Average Rating',\n",
    "                          'Description', 'Duration (Minutes)', 'actors_downcased', 'directors_downcased', 'title_downcased',\n",
    "                           'Language(s)', 'tags_num']\n",
    "                        \n",
    "    \n",
    "    df_display = df_display[['Title', 'Year', 'Description','Duration (Minutes)', 'Genres', 'Actors', 'Director(s)', \n",
    "                             'Production Company', 'Filming Countries', 'Language(s)', 'Tags',\n",
    "                             'Number of Ratings', 'Average Rating', 'weighted_avg', 'actors_downcased', 'directors_downcased',\n",
    "                            'title_downcased', 'movieId', 'title_year', 'decade', 'tags_num']]\n",
    "    \n",
    "\n",
    "    return df_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # load data\n",
    "    df, movie_ratings, links, imdb_movies = load_data()\n",
    "    \n",
    "    # calculate weighted average for sorting\n",
    "    df = weighted_avg(movie_ratings, df)\n",
    "    \n",
    "    # merge in IMDB metadata and tags \n",
    "    df = imdb_merge(imdb_movies, links, df)\n",
    "        \n",
    "    # downcase user input variables so match user input non case-sensitive (keep regular casing for display) \n",
    "    df = downcasing(df)\n",
    "    \n",
    "    # new vars\n",
    "    df = new_vars(df)\n",
    "\n",
    "    # format df for display\n",
    "    df_display = display_dataframe(df)\n",
    "    \n",
    "    # save as parquet\n",
    "    df_display.to_parquet('processed_files/recommendation_display.parq', engine = 'fastparquet', compression = 'GZIP')\n",
    "    \n",
    "    return df_display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['text_top5'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a1371a7978b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-89abcee41cdc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# calculate weighted average for sorting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e578e1c7b35b>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_files/movies_processed.parq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     df = df.drop(columns = ['director', 'actors', 'country', 'description', 'text',\n\u001b[0;32m----> 7\u001b[0;31m                             'text_top5', 'desc_top5', 'tag_cleaned', 'tags_rel', 'tag_top5'])\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# strip year out of title. Match on ( followed by number. () sometimes valid part of title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_eng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\([0-9]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Peritia1/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3998\u001b[0m         )\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Peritia1/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Peritia1/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Peritia1/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['text_top5'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
