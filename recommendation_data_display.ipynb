{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for recommendations display \n",
    "- Merge movie data with all meta-data for display + filtering\n",
    "- Calculate weighted average of ratings\n",
    "    - Primary sort key for non user filter recommendations\n",
    "    - Secondary sort key for same cosine similarity in user-item and item-item recommendations\n",
    "- Downcased versions of variables that user may input (actor, diretor for filters and title for item-item)\n",
    "- Order and rename columns for display - include non-display columns that are needed for setup at the end\n",
    "- Save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import operator\n",
    "import fastparquet\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    ### processed data from recommendation data exploration.ipynb\n",
    "    # movie attributes\n",
    "    df = pd.read_parquet('movies_processed.parq')\n",
    "    # strip year out of title. Match on ( followed by number. () sometimes valid part of title\n",
    "    df['title'] = df.title_eng.apply(lambda row: re.split('\\\\([0-9]', row)[0].strip())    \n",
    "    \n",
    "    # number of and average ratings by movie\n",
    "    movie_ratings = pd.read_parquet('movies_ratings.parq')\n",
    "\n",
    "    ### data to get additional attributes for display\n",
    "    links = pd.read_csv('data/ml-25m/links.csv')\n",
    "    imdb_movies = pd.read_csv('data/imdb/IMDb movies.csv')\n",
    "\n",
    "    ### genome tags for filtering\n",
    "    tags = pd.read_csv('data/ml-25m/genome-tags.csv')\n",
    "    relevance = pd.read_csv('data/ml-25m/genome-scores.csv')\n",
    "    \n",
    "    return df, movie_ratings, links, imdb_movies, tags, relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Average Ratings\n",
    "- \\# of ratings * average rating    \n",
    "    - If just use average rating, many movies only reviewed once or twice. Want highly rated, frequently watched movies   \n",
    "    - This does weight poorly rated, but frequently watched movies higher place than well rated, infrequently movies\n",
    "- Uses:\n",
    "    - Primary sort key for non user filter recommendations\n",
    "    - Secondary sort key for same cosine similarity in user-item and item-item recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def weighted_avg(movie_ratings, df):\n",
    "    # calculate weighted average\n",
    "    movie_ratings['weighted_avg'] = movie_ratings.avg * movie_ratings.cnt\n",
    "\n",
    "    # merge with df with movie attributes\n",
    "    # LEFT merge so keep movies with no ratings (weighted avg = 0) -- can still recommend if fit specific filters\n",
    "    df = pd.merge(df, movie_ratings[['movieId', 'weighted_avg', 'cnt', 'avg']], on = 'movieId', how = 'left')\n",
    "\n",
    "    # replace nulls to 0 \n",
    "    # NOT avg: should display missing if missing\n",
    "    for var in ['weighted_avg', 'cnt']:\n",
    "        df[var] = np.where(df[var].isnull(), 0, df[var])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in additional IMDB attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_merge(imdb_movies, links, df):\n",
    "    # standardize IMDB IDs\n",
    "    imdb_movies['imdbId'] = imdb_movies.imdb_title_id.str.split('tt').str[1]\n",
    "    imdb_movies.imdbId = pd.to_numeric(imdb_movies.imdbId)\n",
    "    \n",
    "    x = len(df)\n",
    "    # merge links to identify IMDB movies\n",
    "    df = pd.merge(df, links[['movieId', 'imdbId']], on = 'movieId')\n",
    "    # merge specific IMDB attributes\n",
    "    df = pd.merge(df, imdb_movies[['imdbId', 'description', 'language', 'duration', 'production_company']])\n",
    "    assert x == len(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in Genome Tags\n",
    "Limit to tags with > 75% relevant in a movie for filtering          \n",
    "__Extension__: incorporate relevant score into weighted average or recommendation score when decide what to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_merge(tags, relevance, df):\n",
    "    # merge tags and relevance scores\n",
    "    tags = pd.merge(tags, relevance, on = 'tagId')\n",
    "\n",
    "    # limit to tags > 75% relevant to a movie \n",
    "    # get list of relevant tags per movie\n",
    "    tags_relevant = tags[tags.relevance > 0.75].groupby('movieId').tag.apply(list).to_frame()\n",
    "    tags_relevant.columns = ['tags']\n",
    "\n",
    "    # merge with dataframe\n",
    "    # LEFT merge because want to keep movie even if doesn't have any tags\n",
    "    df = pd.merge(df, tags_relevant, left_on = 'movieId', right_index = True, how = 'left')\n",
    "    # replace missing tags to empty list\n",
    "    df.tags = df.tags.apply(lambda d: d if isinstance(d, list) else [])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcase User Input Variables so can match user input non case-sensitive  \n",
    "Keep non-downcased version for displaying   \n",
    "Filters:\n",
    "- Actors\n",
    "- Directors     \n",
    "    \n",
    "Item-Item input: \n",
    "- Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcasing(df):\n",
    "    df['actors_downcased'] = df.actors_lst.apply(lambda row: [i.lower() for i in row])\n",
    "    df['directors_downcased'] = df.director_lst.apply(lambda row: [i.lower() for i in row])\n",
    "    df['title_downcased'] = df.title.apply(lambda row: row.lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vars(df):\n",
    "    # round ratings for display (1 decimal)\n",
    "    df.loc[:,'avg'] = df.loc[:,'avg'].round(1)\n",
    "    df['avg'] = df['avg'].apply(str)\n",
    "    \n",
    "    # decade to filter by \n",
    "    def rounddown(row):\n",
    "        return int(math.floor(row / 10.0)) * 10\n",
    "    df['decade'] = df.year.apply(lambda row: rounddown(row))\n",
    "    # convert to string for filtering with lists\n",
    "    df.decade = df.decade.apply(str)\n",
    "    \n",
    "    # language to list\n",
    "    for var in ['language']:\n",
    "        df[var + '_lst'] = df[var].str.split(', ')\n",
    "        df[var + '_lst'] = df[var + '_lst'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrame for Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataframe(df):\n",
    "    \n",
    "    df_display = df.copy()\n",
    "    \n",
    "    # drop columns\n",
    "    df_display = df_display.drop(columns = ['imdbId', 'language'])\n",
    "    # rename + reorder columns\n",
    "    df_display.columns = ['movieId', 'title_year', 'Year', 'Genres', 'Director(s)', 'Actors', 'Filming Countries', 'Title',\n",
    "                          'weighted_avg', 'Number of Ratings', 'Average Rating', 'Description', 'Duration (Minutes)', \n",
    "                          'Production Company', 'Tags', 'actors_downcased', 'directors_downcased', 'title_downcased',\n",
    "                          'decade', 'Language(s)']\n",
    "    df_display = df_display[['Title', 'Year', 'Description','Duration (Minutes)', 'Genres', 'Actors', 'Director(s)', \n",
    "                             'Production Company', 'Filming Countries', 'Language(s)', 'Tags',\n",
    "                             'Number of Ratings', 'Average Rating', 'weighted_avg', 'actors_downcased', 'directors_downcased',\n",
    "                            'title_downcased', 'movieId', 'title_year', 'decade']]\n",
    "\n",
    "\n",
    "    return df_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # load data\n",
    "    df, movie_ratings, links, imdb_movies, tags, relevance = load_data()\n",
    "    # calculate weighted average for sorting\n",
    "    df = weighted_avg(movie_ratings, df)\n",
    "    # merge in IMDB metadata and tags \n",
    "    df = imdb_merge(imdb_movies, links, df)\n",
    "    df = genome_merge(tags, relevance, df)\n",
    "    # downcase user input variables so match user input non case-sensitive (keep regular casing for display) \n",
    "    df = downcasing(df)\n",
    "    # new vars\n",
    "    df = new_vars(df)\n",
    "\n",
    "    # format df for display\n",
    "    df_display = display_dataframe(df)\n",
    "    \n",
    "    # save as parquet\n",
    "    df_display.to_parquet('recommendation_display.parq', engine = 'fastparquet', compression = 'GZIP')\n",
    "    \n",
    "    return df_display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
