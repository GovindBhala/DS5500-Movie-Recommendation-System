{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Evaluate Recommendation Models\n",
    "Functionalized code such that different content models are imported as modules and then standard evaluation functions are called and the results are saved to a text file.   \n",
    "The following markdown describes the various parameters that must be set depending on the model being evaluated \n",
    "\n",
    "- 5 metrics: personalization, precision & recall @K, personal diversity, global diversity, average rating \n",
    "- For all metrics, calculate on a random subset of users and take average value. For personalization, take average across k sets (folds) of random users because comparing users to each other.    \n",
    "- Set seeds such that evaluate different models on the same set of users \n",
    "- Record results from each model in a text file to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Described more thoroughly with visualizations of matrix multiplication in Methodological Appendix\n",
    "\n",
    "- Personalized recommendations: provide materially different sets of recommendations for different users\n",
    "- Accurate recommendations: high precision and recall based on test/train split of user ratings\n",
    "- Personal diversity: provide variety of recommendations to each individual user\n",
    "- Average rating: recommend high quality movies with high average ratings\n",
    "- Global diversity: recommend movies in the long tail. Do not only recommend popular movies because this will not increase overall viewership, engagement with the streaming platform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow of Model Building/Testing\n",
    "1. Content models with different combinations of metadata\n",
    "2. Combined content models where some subset of movies are evaluated using one model and another subset with another\n",
    "    - Best result is used for item-item recommendations in UI\n",
    "3. Combined collaborative filtering and content models where some subset of movies are evaluated with collaborative filtering and another subset with a content model \n",
    "    - Best result is used for personalized recommendations in UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To: Import Recommendation System\n",
    "\n",
    "1)  Convert recommendation system notebook to .py\n",
    "\n",
    "2) Import function using:\n",
    "\n",
    "from <name.py> import <name of the recomendation function>\n",
    "    \n",
    "example: from contentbasedrecommendationsystem import user_content_recommendations\n",
    "    \n",
    "3) recommendation_system: give the name of the recommendation system, you want to get the evaluations for   \n",
    "    \n",
    "    \n",
    "## How to: Run different types of models\n",
    "- Individual content model with full data:\n",
    "    - df1 = sparse dataset\n",
    "    - cols1 = columns from df1\n",
    "    - movieIds = moviesIds (row names) from df1\n",
    "    - keep_movies = movieIds  \n",
    "    - keep_movies1 = []\n",
    "    - keep_movies2 = []\n",
    "    - recommendation_system = content_based_recommendations.user_content_recommendations\n",
    "    - df2 = False, cols2 = False, recommendation_system_input1, recommendation_system_input2 = False\n",
    "    - list_user = set(ratings.userId)\n",
    "- Individual content model with specific subsets of movies:\n",
    "    - keep_movies = subset of movies (likely either movieIds_tags or movieIds_notags)\n",
    "        - Evaluate on subset\n",
    "    - keep_movies1 = same subset \n",
    "        - Generate recommendations only from subset\n",
    "    - Else same\n",
    "- Combined content model with two different input datasets\n",
    "    - df1 = sparse dataset1 , df2 = sparse dataset2\n",
    "    - cols1 = columns from df1, col2 = columns from df2\n",
    "    - keep_movies = movieIds  (evaluate on all movies)\n",
    "    - keep_movies1 = subset 1\n",
    "    - keep_movies2 = subset 2\n",
    "    - keep_movies = movieIds (row names) from df1 or df2 -- identical \n",
    "    - recommendation_system_input1 = content_based_recommendations.user_content_recommendations\n",
    "    - recommendation_system_input2 = False\n",
    "    - recommendation_system = content_based_recommendations_combine.content_models_combine\n",
    "    - list_user = set(ratings.userId)\n",
    "- Collaborative model\n",
    "    - df1 = sparse dataset1 (baseline content) \n",
    "        - Evaluate personal diversity based on baseline features\n",
    "    - df2 = collaborative filtering pretrained\n",
    "    - keep_movies = collab_predictions.movieId.unique()\n",
    "    - keep_movies1, keep_movies2 = []\n",
    "    - recommendation_system = collab_recommendations.collab_recommendations\n",
    "    - df1, cols1, recommendation_system_input1, recommendation_system_input2 = False\n",
    "    - list_user = set(df2.userId)\n",
    "- Combined content and collaborative model\n",
    "    - df1 = sparse dataset1, df2 = collab_predictions (pre-computed predictions)\n",
    "    - keep_movies = movieIds \n",
    "    - keep_movies1, keep_movies2 = []\n",
    "        - Kept movies calculated at a user level\n",
    "    - recommendation_system_input1 = content_based_recommendations.user_content_recommendations\n",
    "    - recommendation_system_input2 = collab_recommendations.collab_recommendations\n",
    "    - recommendation_system = recommendation_system = collab_content_recommendations_combine.collab_content_combine\n",
    "    - list_user = set(df2.userId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Summary\n",
    "\n",
    "### Content Systems: One Model\n",
    "- content_initial_eval (processed_df_sparse): genre, actor, director. Cosine similarity between movies\n",
    "- __Baseline__: contentv2_noMovieNorm_eval (processed_df_sparse): same data, but no normalization of movie vector (true for all others)\n",
    "- __Description TFIDF__: content_desc_eval (processed_df_desc): top 5 TF-IDF tokens from movie description\n",
    "    - Add Genre tokens: content_desc_genre_eval (processed_df_desc_genre_sparse): description tokens and genre\n",
    "- __All meta-data__: content_all_meta_eval (processed_df_all_meta_sparse): genre, actor, director, decade, country, production company \n",
    "    - Try also with each individual feature in the \"all\" version: content_ (genre, actors_directors, decade, country, production) _eval\n",
    "    - content_baseline_plus_prod_eval: genre, actors, director, production company \n",
    "        - country and decade individually perform poorly individually\n",
    "- __Tags TFIDF__: content_tags_eval (processed_df_tags_sparse): top 5 TF-IDF genome tags\n",
    "- __Tags Relevant__: content_tags_rel_eval (processed_df_tags_rel_sparse): top 5 genome tags by relevance score\n",
    "    - __Tags Relevant + Baseline__: content_baseline_tags_rel_eval (processe_df_baseline_tags_rel_sparse): top 5 tags by relevance + baseline features. Attempt to overcome long tail problem\n",
    "    - __Text TFIDF__: content_text_eval (processed_df_text_sparse): top 5 TF-IDF text field (tags + description). Attempt to overcome long tail problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Personalization | Precision@10 | Recall@10 | Personal diversity | Global diversity | Average rating\n",
    "| --- | --- | --- | --- | --- | --- | --- \n",
    "| Baseline | 0.99 | 0.02 | 0.007 | 0.52 | 6.4 | 3.2\n",
    "| All meta-data | 0.99 | 0.02 | 0.006 | 0.42 | 1.05 | 3\n",
    "| Description TFIDF | 0.99 | 0 | 0 | 0.62 | 1.1 | 3.1\n",
    "| Tags TFIDF | 0.96 | 0.075 | 0.02 | 0.36 | 415 | 3.8\n",
    "| Tags Relevant | 0.98 | 0.06 | 0.02 | 0.60 | 524 | 3.5\n",
    "| Text TFIDF | 0.96 | 0.085 | 0.02 | 0.32 | 647 | 3.8\n",
    "| Tags Relevant + Baseline | 0.99 | 0.045 | 0.02 | 0.64 | 116 | 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Baseline (genre, actor, director): best set of metadata \n",
    "    - Adding in combinations of country, decade, and production company worsen performance -- unimportant features to people's opinions of a movie\n",
    "    - Actors and directors important to include with genre, else no differentiation between movies that have the same genre list\n",
    "- Description tokens perform poorly (precision, recall 0)\n",
    "- Genome tagging performs well in terms of performance (precision, recall) and for personalization, personal diversity,  average rating\n",
    "    - However, worse for global diversity because 75% of movies do not have tagging, and tags heavily biased towards movies with many ratings.\n",
    "    - Top 5 relevant genome tags better than top 5 tf-idf tags in personal diversity. Tags TFIDF better (slightly) in precision, recall, average rating\n",
    "    - Tags capture most important information from other meta-data because include info about most important actors, genres, plot themes\n",
    "- Combining tags with other metadata to increase coverage (baseline metadata, description tokens) worsens performance\n",
    "    - Metadata: assuming these movies don't have info related to that tag. Not a valid assumption, just not labeled\n",
    "    - Description: still not recommending tail even though have description for those. However, for the more popular movies, adding description into the text tfidf does seem to improve performance\n",
    "    \n",
    "    \n",
    "Based on the above, overall conclusion is that genome tagging based on relevance does the best in performance but poor global diversity. Prompted following design: Two separate models for movies with tags and movies without tags. Half recommendations from one, half from the other \n",
    "- Performance and credibility from tag model among popular movies\n",
    "    - Also, people tend to expect recognizable movies in their recommendations so lends to credibilty of system. Preps them to be accepting of the long tail that will increase our overall streaming\n",
    "- Access to long tail for baseline model among untagged, less popular movies       \n",
    "--> exploration and exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Systems: Two Models       \n",
    "(1) Evaluate models on relevant dataset     \n",
    "- __Relevant Tags Only__: content_tags_rel_only_eval (processed_df_tags_rel_sparse + keep_cols = movieIds_tags): top 5 genome tags by relevance score ONLY with movies that have tags\n",
    "- __TFIDF Tags Only__: content_tags_only_eval (processed_df_tags_sparse + keep_cols = movieIds_tags): top 5 genome tags by tfidf ONLY with movies that have tags\n",
    "- __TFIDF Text Tags Only__: content_text_tagsonly_eval (processed_df_text_sparse + keep_cols = movieIds_tags): top 5 tags+description fields by tfidf ONLY with movies that have tags\n",
    "- __Baseline no tags__: content_baseline_notags_eval (processed_df_sparse + keep_cols = movieIds_notags): basline model (genre, actor, director) only for movies without tags (long tail) \n",
    "\n",
    "(2) Evaluate combined models on full dataset   \n",
    "- __Combined Relevant__: content_twomodels_tags_rel_eval: combination of __Baseline no tags__ and __TFIDF Tags Only__ models using content_based_recommendations_combine system. df1 = baseline no tags, df2 = tags (tfidf) tags\n",
    "- __Combined TFIDF__: content_twomodels_tags_eval: combination of prior __Baseline no tags__ and __TFIDF Tags Only__ models using content_based_recommendations_combine system. df1 = baseline no tags, df2 = tags (relevant) tags\n",
    "- __Combined Text__: content_twomodels_text_eval: combination of prior __Baseline no tags__ and __TFIDF Text Only__ models using content_based_recommendations_combine system. df1 = baseline no tags, df2 = text (tfidf) tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Personalization | Precision@10 | Recall@10 | Personal diversity | Global diversity | Average rating\n",
    "| --- | --- | --- | --- | --- | --- | --- \n",
    "| Relevant Tags Only | 0.98 | 0.03 | 0.007 | 0.59 | 356 | 3.5\n",
    "| TFIDF Tags Only | 0.96 | 0.07 | 0.008 | 0.36 | 910 | 3.8\n",
    "| TFIDF Text Tags Only | 0.95 | 0.075 | 0.02 | 0.31 | 688 | 3.8\n",
    "| Basline no tags | 0.99 | 0.01 | 0.005 | 0.49 | 1.2 | 3.0\n",
    "| Combined Relevant | 0.99 | 0.025 | 0.01 | 0.67 | 1.85 | 3.25\n",
    "| Combined TFIDF | 0.99 | 0.045 | 0.01 | 0.70 | 1.85 | 3.39\n",
    "| Combined Text | 0.98 | 0.055 | 0.015 | 0.69 | 1.85 | 3.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Genome tagging for movies only with tags: Almost identical evaluations to full data, which makes sense as even with full data effectively just ignored movies without tags. \n",
    "    - Worse recall = likely artifact of different sample users chosen since different universe. These users happened to have rated more movies positively, thus creating a larger denominator for recall. but precision still performing well. \n",
    "    - TFIDF Text is the best on just tags sample \n",
    "- Baseline for movies without tags: compared to full data, slightly worse performance in all stats. To be expected since only evaluating on long tail movies. For example, if rarely viewed then low likelihood that they are in the user's test set for precision, recall \n",
    "- Combined: performance in between two individual models. Higher personal diversity (evaluated on baseline characteristics because available for all movies)\n",
    "    - Better than any single models that consider all movies \n",
    "    \n",
    "__Best Content Model:__ Combined Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering, Content Combined Model\n",
    "- Collab filtering is only evaluated on movies with more than 50 ratings and a subset of users out of users that have given at least 20 users. Thus all other movie recommendations will be generated from a content model \n",
    "\n",
    "(1) Which content model(s) to use on movies not included in collab filtering?\n",
    "- __Baseline__: content_baseline_nocollab_eval. Baseline content model on movies not included in collaborative filtering predictions\n",
    "    - keep_movies = set(movieIds).difference(set(collab_predictions.movieId.unique())) \n",
    "    - keep_movies1 = set(movieIds).difference(set(collab_predictions.movieId.unique())) \n",
    "- __Combined Text__: (baseline no tags + TFIDF text tags)  content_combined_tags_nocollab_eval. Combined text model on movies not included in collaborative filtering - further break down into movies with and without tags\n",
    "    - keep_movies = set(movieIds).difference(set(collab_predictions.movieId.unique())) \n",
    "    - keep_movies1 = set(movieIds_notags).difference(set(collab_predictions.movieId.unique())) \n",
    "    - keep_movies2 = set(movieIds_tags).difference(set(collab_predictions.movieId.unique())) \n",
    "    \n",
    "(2) Combined collaborative + (best) content model from above\n",
    "- __Combined Collaborative+Content__: collab_content_combined. Baseline content model + collaborative filtering model. Content recommendations for any movies that don't have a collaborative prediction for each individual user.  \n",
    "    - df1 = baseline, df2 = collab_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Personalization | Precision@10 | Recall@10 | Personal diversity | Global diversity | Average rating\n",
    "| --- | --- | --- | --- | --- | --- | --- \n",
    "| Baseline | 0.99 | 0.01 | 0.005 | 0.54 | 2.3 | 3.1 \n",
    "| Combined Text | 0.91 | 0.005 | 0.0003 | 0.75 | 2.95 | 3.3 \n",
    "| Combined Collaborative+Content | 0.86 | 0.5 | 0.2 | 0.75 | 6.95 | 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baseline performs better than combined text for the non-collaborative filtering movies for precision, recall.\n",
    "    - Makes sense because there are a small number of movies not in collab filtering with tags since tags are biased towards popular movies. We are then forcing half of our recommendations to be from this small subset, where it is unlikely that is a \"relevant\" movie\n",
    "- Combined collaborative + content performs similarly to best combined content model for all non-precision, recall metrics except personalization. Better in personal diversity. Preicison and recall significantly better.  Personalizations is still high despite decrease.\n",
    "    - Clearly best model\n",
    "\n",
    "\n",
    "__Best Personalization Model:__ Combined Collaborative + Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import operator\n",
    "import scipy.spatial.distance as distance\n",
    "from sklearn import metrics \n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import fastparquet\n",
    "import pickle\n",
    "import scipy\n",
    "import sklearn\n",
    "from surprise import SVD, Dataset, Reader, KNNBaseline\n",
    "import recommendation_models.content_based_recommendations\n",
    "import recommendation_models.content_based_recommendations_combine\n",
    "import recommendation_models.collab_content_recommendations_combine\n",
    "import recommendation_models.collab_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings and movie ratings aggregation data\n",
    "ratings = pd.read_parquet('processed_files/ratings_sample.parq')\n",
    "ratings = ratings.reset_index()\n",
    "movies_ratings = pd.read_parquet('processed_files/movies_ratings.parq')\n",
    "movies_ratings = movies_ratings.rename(columns={\"avg\": \"Average_Ratings\"})\n",
    "movies_ratings['weighted_avg'] = movies_ratings.cnt * movies_ratings.Average_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify sparse matricies of features to use for content attributes \n",
    "df1 = scipy.sparse.load_npz(\"processed_files/processed_df_sparse.npz\")\n",
    "#df2 = scipy.sparse.load_npz(\"processed_files/processed_df_text_sparse.npz\")\n",
    "#df2 = False\n",
    "\n",
    "# preloaded collaborative filtering predictions\n",
    "collab_predictions = pd.read_parquet('Predictions/KNN_predictions_df.parq')\n",
    "collab_predictions = collab_predictions.rename(columns = {'est':'prediction', 'uid':'userId', 'iid':'movieId'})\n",
    "collab_predictions = collab_predictions.drop(columns = ['r_ui', 'details.actual_k', 'details.was_impossible'])\n",
    "df2 = collab_predictions.copy()\n",
    "\n",
    "with open('processed_files/sparse_metadata', \"rb\") as f:\n",
    "    cols1 = pickle.load(f)\n",
    "    movieIds = pickle.load(f)\n",
    "    \n",
    "#with open('processed_files/sparse_metadata_text', \"rb\") as f:\n",
    "#    cols2 = pickle.load(f)\n",
    "#    movieIds = pickle.load(f)\n",
    "cols2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movieId lists for movies with and without tags so can specify which movies to keep for which models\n",
    "with open('processed_files/movieIds_tags', \"rb\") as f:\n",
    "    movieIds_tags = pickle.load(f)\n",
    "with open('processed_files/movieIds_notags', \"rb\") as f:\n",
    "    movieIds_notags = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which movies we want to keep for evaluation and for generating recommendations \n",
    "keep_movies = collab_predictions.movieId.unique() # evaluate against\n",
    "keep_movies1 = [] # generate recs from model 1 (df1) - if [] then all movies\n",
    "keep_movies2 = [] # generate recs from model 2 (df2) - if [] then all movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of users to consider for random sampling\n",
    "#list_user = set(ratings.userId)\n",
    "list_user = set(collab_predictions.userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use to get a subset of columns from processed_df_all_meta_sparse\n",
    "#index = [cols.index(i) for i in cols if i.startswith('production') | i.startswith('genres') | i.startswith('actors') |\n",
    "#        i.startswith('director')]\n",
    "#df = df[:, index]\n",
    "#cols = [cols[i] for i in index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters\n",
    "- n = # number of users\n",
    "- top_n = # top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "top_n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top n recommendations with movieIds\n",
    "def user_movie_id(movies,n):\n",
    "    return movies['movieId'][:n]\n",
    "\n",
    "# get top n recommendations with average raitngs\n",
    "def user_avg_rating(movies,n):\n",
    "    return movies['Average_Ratings'][:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify recommendation system(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommendation_system_input1 = recommendation_models.content_based_recommendations.user_content_recommendations\n",
    "#recommendation_system_input2 = recommendation_models.collab_recommendations.collab_recommendations\n",
    "recommendation_system_input1 = False\n",
    "recommendation_system_input2 = False\n",
    "\n",
    "#recommendation_system = recommendation_models.content_based_recommendations.user_content_recommendations\n",
    "#recommendation_system = recommendation_models.content_based_recommendations_combine.content_models_combine\n",
    "recommendation_system = recommendation_models.collab_recommendations.collab_recommendations\n",
    "#recommendation_system = recommendation_models.collab_content_recommendations_combine.collab_content_combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open file to record evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"evaluations/collab_only_eval_tst.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalization \n",
    "How different are recommendations for different users? Are our recomendations actually personalized?    \n",
    "     \n",
    "K fold cross-validation across several sets of users\n",
    "- Generate recommendations for n users\n",
    "- Create movie matrix with row = user, column = movie, value = 1/0 for if movie recommended\n",
    "- Cosine similarity between users. Average of elements above the diagonal\n",
    "- Repeat for k folds and take overall average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return user predictions for each user in users_list\n",
    "# return list of all predictions for users in user_list\n",
    "def get_users_prediction(users_list,top_n,users_prediction,recommendation_system, df1, ratings, movieIds, movies_ratings,\n",
    "                         keep_movies1, df2 = False, keep_movies2 = False,\n",
    "                         recommendation_system_input1 = False, recommendation_system_input2 = False):\n",
    "    for i in users_list:\n",
    "        # generate recommendations \n",
    "        recommendation = recommendation_system(i, df1, ratings, movieIds, movies_ratings, keep_movies1, \n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "        # top_n recommendations\n",
    "        prediction = user_movie_id(recommendation,top_n).astype(int).values\n",
    "        # append to list of predictions\n",
    "        users_prediction = users_prediction.append(pd.Series(prediction),ignore_index=True)\n",
    "        \n",
    "    return users_prediction\n",
    "\n",
    "# generate movie matrix: \n",
    "# row = user; column = movie ; value = 0 movie not recommended, 1 movie recommended\n",
    "def user_matrix(users_pred):\n",
    "    data_melt= pd.DataFrame(data=users_pred).reset_index().melt(id_vars='index', value_name='movieId',)\n",
    "    data_melt = data_melt[['index', 'movieId']].pivot(index='index', columns='movieId', values='movieId')\n",
    "    cols = data_melt.columns\n",
    "    \n",
    "    # replace na with 0\n",
    "    for i in cols:\n",
    "        data_melt[i] = np.where(data_melt[i].isna(), 0, 1)\n",
    "        \n",
    "    return data_melt\n",
    "\n",
    "# generating cosine similarity between the users. Same movie recommended for multiple users? \n",
    "# then getting the indicies of elements above diagonal (giving diagonal offsert =1 in triu_indices)\n",
    "# calculating the avg of the element above diagonal \n",
    "# Personalization means 1 - similarity\n",
    "# higher the personalization score, better the recommendation system in recommending personalized movies (minimize similarity)\n",
    "def personalization(users_matrix,n):\n",
    "   \n",
    "    # cosine similiarity\n",
    "    users_sim = metrics.pairwise.cosine_similarity(users_matrix)\n",
    "    \n",
    "    # upper triangle\n",
    "    iu1 = np.triu_indices(n,k=1)\n",
    "    \n",
    "    # average in upper \n",
    "    similarity_avg = np.mean(users_sim[iu1])\n",
    "    \n",
    "    # 1 - similarity. Want to maximize score (minimize similarity)\n",
    "    personalization_score = 1 - similarity_avg\n",
    "\n",
    "    return personalization_score\n",
    "\n",
    "\n",
    "# evaluate personalization on k random folds. Mean. \n",
    "def cross_fold_eval(unique_users,recommendation_system, movies_ratings, df1, keep_movies1, \n",
    "                    df2 = False, keep_movies2 = False, \n",
    "                    recommendation_system_input1 = False, recommendation_system_input2 = False, \n",
    "                    k_fold=10,n=10,top_n=10):\n",
    "    \n",
    "    # initiate to sum scores across folds (take average at end)\n",
    "    kfold_personalization=0\n",
    "    \n",
    "    # look through k folds\n",
    "    for i in range(k_fold):\n",
    "        \n",
    "        # generate list of n random users\n",
    "        users_list = random.sample(unique_users, n)\n",
    "        \n",
    "        # columns: top_n recommendations\n",
    "        # users_prediction:  top_n recommendations for n users. \n",
    "        column_names = list(range(top_n))\n",
    "        users_prediction = pd.DataFrame(columns = column_names)\n",
    "                \n",
    "        # getting predictions for all sampled users\n",
    "        users_pred = get_users_prediction(users_list,top_n,users_prediction,recommendation_system, \n",
    "                                          df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                          df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "        \n",
    "        # getting user by movies matrix with binary indicators 0: movie not recommended, 1: movie got recommended\n",
    "        users_matrix = user_matrix(users_pred)\n",
    "        \n",
    "        # find personalization score based on movie matrix. Sum across folds \n",
    "        kfold_personalization+=personalization(users_matrix,n)\n",
    "        \n",
    "        \n",
    "    # average across all folds\n",
    "    kfold_eval = kfold_personalization/k_fold\n",
    "    \n",
    "    # write to file \n",
    "    print(f'Personalization score for {k_fold} folds across {n} users for top {top_n} recommendations: {kfold_eval}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get unique user set \n",
    "# K-fold cross validation for personalization score \n",
    "cross_fold_eval(list_user,recommendation_system, movies_ratings, df1, keep_movies1, df2, keep_movies2,\n",
    "                recommendation_system_input1, recommendation_system_input2, n = n, top_n = top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall \n",
    "- Generate train/test split among users that have at least 20 rated target movies\n",
    "- Generate recommendations on train, see if got any \"correct\" from test. Calculate precision, recall\n",
    "- Average across users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random samples of users who have rated minimum of 20 movies OUT OF target movies (keep_movies)\n",
    "Need enough movie ratings to do a reasonable train/test split. \n",
    "- keep_movies: universe of movie we want to calculate precision and recall in \n",
    "- n_users: Number of users to filter the from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of users who rated at least 20 movies: 1000\n"
     ]
    }
   ],
   "source": [
    "def target_users(ratings, keep_movies, list_user, n_users = 1000):\n",
    "    \n",
    "    # keep users with at least 20 ratings out of target movies (keep_movies)\n",
    "    users_list = ratings[(ratings.movieId.isin(keep_movies)) & (ratings.userId.isin(list_user))\n",
    "                        ].groupby('userId')['userId'].count().reset_index(name=\"rating_count\")\n",
    "    users_list = set(users_list[users_list['rating_count']>=20]['userId'].values)\n",
    "    print(f' Number of users who rated at least 20 movies: {len(users_list)}')\n",
    "    \n",
    "    # random sample of n_users \n",
    "    random.seed(42)\n",
    "    random_users = random.sample(users_list, n_users)\n",
    "    # get the ratings of the random sample of users\n",
    "    users_ratings = ratings[ratings.userId.isin(random_users)]\n",
    "    \n",
    "    return users_ratings, random_users\n",
    "\n",
    "users_ratings, random_users_20 = target_users(ratings, keep_movies, list_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test split - Keeping the users distribution similar\n",
    "Select subset of users and then split each user's ratings into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(random_users, users_ratings):\n",
    "    \n",
    "    # creating train/test empty dataframe\n",
    "    train = pd.DataFrame(columns=['index','userId', 'movieId', 'rating','timestamp'])\n",
    "    test = pd.DataFrame(columns=['index','userId', 'movieId', 'rating','timestamp'])\n",
    "\n",
    "    # spliting each user data equally in train test\n",
    "    for i in random_users:\n",
    "        \n",
    "        #getting individual user index in the users_ratings list\n",
    "        random_index =set(users_ratings[users_ratings['userId'] == i].index.values)\n",
    "\n",
    "        # dividing the user ratings count/2\n",
    "        n_len = np.math.floor(len(random_index)/2)\n",
    "\n",
    "        # getting index for train data: random half of that user's ratings\n",
    "        train_ind = set(random.sample(random_index, n_len))\n",
    "\n",
    "        # getting index for test data by removing train index from all index for that user\n",
    "        test_ind = set(random_index-train_ind)\n",
    "\n",
    "        # assign indexes to train, test set\n",
    "        df_train = users_ratings.loc[train_ind]\n",
    "        df_test = users_ratings.loc[test_ind]\n",
    "        \n",
    "        # appending that user data to train/test df\n",
    "        train = train.append(df_train)\n",
    "        test = test.append(df_test)\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(random_users_20, users_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average Precision, Recall across random users\n",
    "- Generate recommendations based on training data. See if get movies from the test data that the user actually liked\n",
    "- Relevant item: Has in test with rating >= 2 \n",
    "    - Generous definition of relevant because hard to get precision, recall without user feedback. \n",
    "    - Limit to movies in keep_movies set. Only movies possibly being generated by model\n",
    "- Precision@k = (# of recommended items @k that are relevant) / (# of recommended items @k)\n",
    "- Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision@K = (# of recommended items @k that are relevant) / (# of recommended items @k)\n",
    "def calc_precision_k(recommended_relevant_count,recommended_count):\n",
    "    precision_k = recommended_relevant_count/recommended_count\n",
    "    return precision_k\n",
    "\n",
    "# Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)   \n",
    "def calc_recall_k(recommended_relevant_count,relevant_count):\n",
    "    if relevant_count==0:\n",
    "        return 0\n",
    "    else:\n",
    "        recall_k = recommended_relevant_count/relevant_count\n",
    "        return recall_k\n",
    "    \n",
    "# average precision and recall across random users\n",
    "def avg_precision_recall(random_userId, recommendation_system, train, test, keep_movies, movies_ratings, df1, keep_movies1, \n",
    "                         df2 = False, keep_movies2 = False, \n",
    "                         recommendation_system_input1 = False, recommendation_system_input2 = False,\n",
    "                         top_n = 10, k = 5):\n",
    "    \n",
    "    # lists to record\n",
    "    avg_precision=[]\n",
    "    avg_recall =[]\n",
    "    tot_rec_rel = []\n",
    "    \n",
    "    # look through user subset\n",
    "    for i in random_userId:\n",
    "        \n",
    "        # generate recommendations \n",
    "        recommendation = recommendation_system(i, df1, train, movieIds, movies_ratings, keep_movies1,\n",
    "                                               test, keep_movies2, recommendation_system_input1, recommendation_system_input2,\n",
    "                                               precision = True)\n",
    "        # getting the recommended movies @k\n",
    "        recommended_movies = set(recommendation[:k].movieId)\n",
    "\n",
    "        # number of recommended movie @k\n",
    "        recommended_count = k\n",
    "        \n",
    "        # getting relevant movies, where ratings >= 2\n",
    "        # limit to keep movies as these are the only movies being possibly produced by the recommendation system \n",
    "        relevant_movies =set(test[(test.movieId.isin(keep_movies)) &\n",
    "                                  (test['userId']==i) & (test['rating']>=2) ]['movieId'].values)\n",
    "        # Total number of relevant movie\n",
    "        relevant_count = len(relevant_movies)\n",
    "        \n",
    "        # Getting movies that are relevant and recommended (set intersection)\n",
    "        recommended_relevant_movies = recommended_movies.intersection(relevant_movies)\n",
    "        \n",
    "        # number of relevant recommended movies\n",
    "        recommended_relevant_count = len(recommended_relevant_movies)\n",
    "        \n",
    "        # calculate precision, recall\n",
    "        precision_k = calc_precision_k(recommended_relevant_count,recommended_count)\n",
    "        recall_k = calc_recall_k(recommended_relevant_count,relevant_count)\n",
    "        \n",
    "        # record \n",
    "        avg_precision.append(precision_k)\n",
    "        avg_recall.append(recall_k)\n",
    "        tot_rec_rel.append(recommended_relevant_count) # absoute number of recommended relevant movies \n",
    "        \n",
    "    # take average across n users \n",
    "    precision_avg = np.mean(avg_precision)\n",
    "    recall_avg = np.mean(avg_recall)\n",
    "    rec_rel_avg = np.mean(tot_rec_rel)\n",
    "\n",
    "    return precision_avg, recall_avg, rec_rel_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130332"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of elligible users, get random subset of n from training data (same users as in test data)\n",
    "\n",
    "random.seed(42)\n",
    "train_user_id = set(train.userId.values)\n",
    "random_userId = random.sample(train_user_id, n)\n",
    "random_userId[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluate at several values of K__    \n",
    "Most informative is k = 10 because generally generating 10 recommendations for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "precision_k,recall_k, rec_rel_avg = avg_precision_recall(random_userId, recommendation_system,\n",
    "                                                         train, test, keep_movies, movies_ratings, \n",
    "                                                         df1, keep_movies1, df2, keep_movies2, \n",
    "                                                         recommendation_system_input1, recommendation_system_input2,\n",
    "                                                         top_n, k)\n",
    "\n",
    "print(f'Avg Precision at {k} for {n} users: {precision_k}', file = f)\n",
    "print(f'Avg Recall at {k} for {n} users: {recall_k}', file = f)\n",
    "print(f'Avg Number of relevant recommendations at {k} for {n} users: {rec_rel_avg}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "precision_k,recall_k, rec_rel_avg = avg_precision_recall(random_userId, recommendation_system,\n",
    "                                                         train, test, keep_movies, movies_ratings, \n",
    "                                                         df1, keep_movies1, df2, keep_movies2, \n",
    "                                                         recommendation_system_input1, recommendation_system_input2,\n",
    "                                                         top_n, k)\n",
    "print(f'Avg Precision at {k} for {n} users: {precision_k}', file = f)\n",
    "print(f'Avg Recall at {k} for {n} users: {recall_k}', file = f)\n",
    "print(f'Avg Number of relevant recommendations at {k} for {n} users: {rec_rel_avg}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "precision_k,recall_k, rec_rel_avg = avg_precision_recall(random_userId, recommendation_system,\n",
    "                                                         train, test, keep_movies, movies_ratings, \n",
    "                                                         df1, keep_movies1, df2, keep_movies2, \n",
    "                                                         recommendation_system_input1, recommendation_system_input2,\n",
    "                                                         top_n, k)\n",
    "print(f'Avg Precision at {k} for {n} users: {precision_k}', file = f)\n",
    "print(f'Avg Recall at {k} for {n} users: {recall_k}', file = f)\n",
    "print(f'Avg Number of relevant recommendations at {k} for {n} users: {rec_rel_avg}', file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Diversity\n",
    "How different are the movies that we are recommending to users? Content models tend to \"profile\" people and result in over-specialization where only provide one kind of recommendation. Ideally would provide some variety.   \n",
    "- Generate recommendations for random user \n",
    "- Get \"profile\" of each recommended movie (non zero features)\n",
    "- Find cosine similarity between recommended movies. Transform to distance so maximize\n",
    "- Average over n users\n",
    "\n",
    "\n",
    "__NOTE:__ movies are compared based on the features in the current model. ie if model based on tags features, then looking at diversity of tags. If model based on genres and actors, then looking at diversity of actors and genres.   \n",
    "- For combined models, diversity based off of baseline features in df1 (genre, actors, directors) so that all movies equally comparable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_diversity(top_n, rand_user, recommendation_system, movies_ratings, df1, df2, keep_movies1, keep_movies2, \n",
    "                       recommendation_system_input1, recommendation_system_input2, cols1):\n",
    "\n",
    "    length = len(rand_user)\n",
    "    \n",
    "    # storing diversity for n users\n",
    "    diversity =[]\n",
    "    # find diversity for each user\n",
    "    for u in range(length):\n",
    "        \n",
    "        # getting recommended movies\n",
    "        recommendation = recommendation_system(rand_user[u], df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "        \n",
    "        # get top_n recommended movies \n",
    "        prediction = user_movie_id(recommendation,top_n).astype(int).values\n",
    "        predicted_index = [movieIds.index(i) for i in prediction] \n",
    "        user_df = df1[predicted_index, :]\n",
    "        user_movie_features = pd.DataFrame()\n",
    "        \n",
    "        # get movie profiles: getting only the columns that have any value 1\n",
    "        for i in range(len(prediction)):\n",
    "            nonzero_cols = [cols1[j] for j in user_df[i,:].nonzero()[1]]\n",
    "            d = {k:1 for k in nonzero_cols}\n",
    "            d = pd.DataFrame(data = d, index = [prediction[i]])    \n",
    "            user_movie_features = pd.concat([user_movie_features, d])\n",
    "\n",
    "        # replace NaN with 0\n",
    "        user_movie_features = user_movie_features.fillna(0)\n",
    "        \n",
    "        # generating cosine similarity between the recommended movies\n",
    "        sim = metrics.pairwise.cosine_similarity(np.asmatrix(user_movie_features))\n",
    "\n",
    "        # above diagonal elements. Take average (1 - similarity so get distance, which we want to maximize)\n",
    "        iu1 = np.triu_indices(user_movie_features.shape[0],k=1)\n",
    "        avg = 1 - np.mean(sim[iu1])\n",
    "        \n",
    "        # keep track across n users\n",
    "        diversity.append(avg)\n",
    "        \n",
    "    # calculating avg diversity over n users\n",
    "    avg_diversity = np.mean(diversity)\n",
    "\n",
    "    return avg_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get list of n random users \n",
    "random.seed(42)\n",
    "rand_user = random.sample(list_user, n)  \n",
    "\n",
    "avg_diversity = personal_diversity(top_n, rand_user, recommendation_system, movies_ratings, \n",
    "                                   df1, df2, keep_movies1, keep_movies2, \n",
    "                                   recommendation_system_input1, recommendation_system_input2, cols1)\n",
    "print(f'Average diversity over {n} users for their top {top_n} recommendations (0 = identical): {avg_diversity}', file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Rating \n",
    "Want to recommend \"good\" movies with high average ratings    \n",
    "\n",
    "- Generate recommendations for random users\n",
    "- Merge in average ratings of the recommended movies\n",
    "- Take average of average ratings \n",
    "- Take average across random sample of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rating(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2, \n",
    "                   recommendation_system, recommendation_system_input1, recommendation_system_input2):\n",
    "    \n",
    "    length = len(rand_user)\n",
    "    avg_rating = []\n",
    "\n",
    "    # loop through users\n",
    "    for u in range(length):\n",
    "        # getting recommended movies\n",
    "        recommendation = recommendation_system(rand_user[u], df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "        # find average all movies' average ratings \n",
    "        prediction = user_avg_rating(recommendation,top_n).values\n",
    "\n",
    "        # keep track across users\n",
    "        avg_rating.append(prediction)\n",
    "\n",
    "    # flatten list \n",
    "        # can recommend movies without ratings so lists may be diff lengths: won't work in np.mean natively\n",
    "    avg_rating = [item for sublist in avg_rating for item in sublist]\n",
    "    \n",
    "    return avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random users out of users that have rated at least one of keep_movies\n",
    "list_user_keepmovies = set(ratings[(ratings.movieId.isin(keep_movies)) & (ratings.userId.isin(list_user))].userId)\n",
    "\n",
    "random.seed(42)\n",
    "rand_user = random.sample(list_user_keepmovies, n)  \n",
    "\n",
    "avg_rating = average_rating(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2,\n",
    "                            recommendation_system, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "print(f'Average movie rating of top {top_n} movies recommended to {n} users: {np.round(np.mean(avg_rating),2)}', file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Graph Distribution of Ratings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ratings - Recommended Movies')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAExCAYAAABf4YTAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de9xlY/3/8dcb43w2DMkYkb5KB0XkpxAiCkkokiIqfSMVkRwjnRTflMa5JpGSJCE5xTgNIYfIYZyHcRyDYZjP74/r2u41a/a+Z90za+997/t+Px+P/dhrX+vaa1977bXXZ61rXeu6FBGYmZnVZZ5uF8DMzIYWBxYzM6uVA4uZmdXKgcXMzGrlwGJmZrVyYDEzs1o5sAxxkkLS6d0uhw1vksbkbfGwNiz7dEk9e9+EpCskTex2OerkwNIBkjbKf6riY6qkmyV9XdJ8c7HsJSUdJmmjGovcE/IfsrhOp0t6TNLZktbsdvls8JE0MW8rT0taoEWePxe2qTGdLeHQMMc7NJsjvwMuBAQsD+wKHAusAew5h8tcEjg0T1/RZP5CwOtzuOxe8AqwR55eCHgf8HlgS0lrR8TdXSuZDVbTgKWBrYFzijMkjQK2zHkW7FB5PkLaJwwZPmPprJsjYlxE/CYifgSsBzwC7CFp2XZ8YERMi4jp7Vj2IPFaXqfjIuKkiPgS8C1gUeCrXS6bDU73Af8mHYCU7Zqf/9KpwkTEqxHxSqc+rxMcWLooIl4EriMdrazaSJc0j6TvSLpK0iRJr0p6SNIvJS1TyLcR8EB+eWjh9H1iIc8s11gaaZI+IOlKSS9KekrSyZIWLZdT0oaSrpX0ci7PcZLeUa4zV7KvpNskvSBpiqS7JZ0iaUQtK62af+Tnt5ZnSNpR0tW5fC9Jul7S9s0WImljSX/N1SbTJN2fv8vIQp75JB0g6c6c52lJf5L0ztKy3rjGIGkHSbfk9XmvpM/nPKMl/UHSM7l84yQtVlrO6Xk5y+Tpp3Le8yQtn/PsKemuXJ7/SNqmxfertC7mYHvZQNI1+fs9IennpEDfrAyS9GVJN+UyvCDpckkbN8m7oKQfKVV3vizpBkkfabbcCk4DPiJpxVL6bsBfgSdblHeMpN/k7/WKpPskHS1p4UKeL+d1tnWT988j6RFJtxTSml5jkfTW/FmPK+0DJubvv0gp30qSTpX0YC7Tk5LGS/rcQFZIrSLCjzY/gI2AAL7ZZN7Ned7qhbQFgeeAU4BvAF/K06+SjrTmz/lGAfvm958L7JIf2xaWFcDppc8M4BbgaeDHwF6karoAxpbybkCqbppEqnLbB7gGmJDzH1bI+92cdj7wlbzcY4A7gUXbsF6vAKY2Sd86l+PMUvr3cvrf8nr7GnB5Ttu7lHcvYAbwcH7fF4Ej83p7TyHf2fn9lwD/CxyVf7upwFqFfGNyvgl5XR5COqP6V07fGXiQtMNr/N4BnFwq1+k5/UbgT3k9Hwu8BlxLOlv7L/Dt/B3vB6YDq8zFuhjI9rIuqRppMnBYXvZ19G3nh5XyjyNV1Z6d18c3ct7XgK1Lef9U2L72zt97Kuk/ERW3mYnA7cBI0v/pwMK89fLytwZ+nqfHFOavTAo4rwA/y+v+9znflcB8Od9SeR38ocnnb5bzf720HU8s5Xsf8HzeJg4jbX8/z589HhiR880H/Ad4AfgBsDuwX95OTq6yTtqyz+vWBw+nB32B5ZC8QS8LvBM4IaffUMovYKEmy9k959+hkDam2R+2ML9VYJkBrFdK/ytpJ7RoIe2G/Cd5SyFtBCm4lAPLzcCdHVyvV+Qdy8j8WAnYNu88AtiykPe9Oe3oJss5D5gCLJZfvzn/ge8ElmySf5783NhJnA2oMP9dpB3jP5v8Ti8CKxfSl83rdwawX+lzziXt/Iq/x+l5OSeU8h6b0x8CFi+VJYDvz8m6mIPtZXwuc/FAaf68HZW3l0/ktD1Ly52PFIAfaKxX0nWIZtvytjk9Km4zE4Hb8/QfgXsK88aSgv58NA8svy1vVzn9Rzl990LaOfl3XaqU9zd5nY0qbccTS/luJQWMxUrpjXW2W+n33b9T/7sqD1eFddbhpCO5J4HbSEc855KOkN4QycsAkuZVavk1ErgsZ1m3hrJcGxHXldIuI/2pxuTPHgWsA/w5Iu4vlG86cFyTZT4PrChpgxrKV9UipHU6mbRT/RNpR/a5iLiwkG9n0h/wDEkjiw/SEfBiwAdy3k/lZRweEc+VPzAiZuTJT+TnoyL/y/P824ALgA0067Wz8yLiwULeycDdpB33CaW8/yQF8TFNvvfPmuQF+HVETCmVZQozVwsOZF00VNlelsvv+3NE3FMow6vAT5t8h11IR9rnlcqwJOkax5hCubfNzz8qLiAiziOtvzlxKvBWSf9P0kLAjqT191o5o6R5SP/Tf5W2K4Dvk36/TxTSzgAWyMtsLGPRnOeiiHiiVaFyNeq7gDOBBUrr5mrSwUmjCvD5/LxxXv+DgluFddZY0pHMCNIZywGko+Np5YySdiBVC6yV8xctVUNZ7m+S9nR+blzHWSU/N/vjNks7iHTE+09Jj5GOxP5KqhJ4tb/C5B3wvIWk1/NOd3amAR/P00uTLr5uxqzXD9cgnQn+p59ljcrPjZ3Zv2bz2auQdih3NZl3O7BNzlP8Hs3W+7PA4zHrBdxn8/MyzKq8nEbeB1osv7iMgayLVp8Hs24vb8nPzZZ7Z5O0NUhBrOVONpfjnrzsGXm67C7gbf0so5WLgMdJF/HfAixOqopsZlnSdaI7yjMi4hlJj9P3/RvLfpK0PZ6Y0z5JOhA6YzblWiM/H54fzYzKn/2gpKOAA4HH87WbfwDnRMSNs/mctnFg6az/RsSlefpvkq4mHYGcCOzUyCRpO1L1yg2kaxoPk3ag85I22DrONPtrgqzScyURca2kVYHNgY3z4zPAwZI2iIhn+nn7jaQ67IYHaX6kXvZ6YZ0i6Q+ks4Wxkm7OR+yQvksAH6X1d7+jkJecvz9z0kS01WdX+T3eEBEDXY5K01XXxUDK1996a7auRAq6n+ln2bf38/7+lj1bEfG6pF+Tag7eAVwXEc0OEgb8GRHxmqQzgX0lrRYR95KCzLPMvsVZ47N+Qvq/N9M4kCAiDpZ0KrAV8EFS8/tvSfphRBwwkHLXxYGliyJivKTfALtKOj4ixudZnyUFko0j4qVGfkn/02wxbSxi4yi12dFg0yPEiJhKqrv+I4Ckr5CqeHanVI1RsjPpPpSGlwda2Pz5MyTtQzpC/jF9VQb/BbYAHupn59HQOBtbK7+vlftIQXQNUtVm0dvzc7MziG4byLoYiPvy8xpN5jVL+y+wOmmHPrXCsj+S85eDXrP/RVWnkmoO1qP/e8meJFXbvaM8Q9JSwAqkBg5FZ5AaL+wqaSzpWuvYJmemZY1tbqaDpv7kqur/A/5P0oLAxcD+kn4SEU1buLWTr7F035Gko8EjCmmvkwLGG7+PJAEHN3l/4w+5dN0Fy/XAE4BtJL1xmq/UdHifcn4VmuEW3FylfBFxTURcWnhcMxfl/i+pfnqzwvWe3+TnoyXNW35PqX76D6QL0IdKWrxJ3sYR5Xn5+cBCGkp3/W8NXF2xOq/TBrIuKss7sOtI28vqheXND3y9yVt+TdrGv99sefkaX8Of8/O3Snm2Zc6qwRplvoe0LR9OqiVolW8G6UxjLUlblGZ/m/Q9/lR6zy2kA45dSGcr8zD7ajBIVbC3A18q/u8alJq4L52nl1CpKX9ETKOveraOavMB8xlLl0XEvZLOAnaW9MGI+Cdpx/ZJ4LJ8qj6CdPFy4Sbvf1rSvcBOku4j1Ve/GBF13eD1TeDvwHhJvyBdLNyBdHEbZj5jukvSdcD1wGOko7g9STvps2oqT1VHk/7QhwObRMSNkg7Nr2+RdE6hjO8j3W09P0BEPCJpX9KZ1r/zb/AgsCLpuskXgFsi4u+Sfk+qxlxK0gWkHhX2Jp1xfq1j33YABrIu5sB+pGtr10g6gdT0eiea7Gsi4g+STgO+Kum9pCrMp0jXHT8ArEa+bhERF0v6C/C5vFO9iHTv116knfAcd+ETEcdXzHoQ6frdefm/cC/wIdIF+qtoHjTOIFVpHUBqgVZuANGsPCHps6TGEbflaq47SP//1YDtSNdUTidVN4+V9EfSmfZU0m+4B3B9dKvniW43SxsOD/q5jyXPX4N0lnJ5Ie2LpOqcaaQLjGNJR/3Nmly+n9T898U8f2JhXqvmxqc3Kcdued5GpfQPk45Ep5EC13GklmkzNXMkHbldRV9b/4dJjRXe26b1egVN7mMpzG/ca7FhIW0rUjXBM4Uy/g34cpP3f4QUVJ/P3/1+4CRgmUKe+Ug7jbvy8p4hncm8s7SsMbRoFk6T5qatfg9yc+N+trHdmsybCFzRJL3SupiD7eVDpGbH0/K2cAJpx9/q+3+W1KptSn7PRFJryR1L+RYi7aQnkapKbyRVRTZdJy22iYnk5sazyTdLc+OcvgrpjO9J0gHT/aSDmIVbLGcUqXlxAN/pZztu9vuvTLr+OjF/1tPATaQzvJUK5Tkxb39TSPuAu0g1IEu0439X5dFoI242IJI+STqz+nREdPpsxMwGMV9jsX4pWbCUNoJU5fEazTu+NLNhzNdYbHYWAB6U9FtSHe4ypDrldwE/iIhJ3SycmQ0+Diw2O9NJNzluQ7q4K1KA2TsiftHNgpnZ4ORrLGZmVitfYzEzs1q5KgwYOXJkjBkzptvFMDPrKTfddNNTETHLIIUdDSySdiX17vkeUvvuF0g3N30vIi4v5d2ddIPZ23K+i0ljJzxcyjea1I58c1IncfcAx0fEKVXLNWbMGCZMmDCnX8vMbFiS9GCz9E6fsRzEzN0vLES6+e7Dkt64H0LSwaSuThoWIPUltaGkdRotkZRGzBtPuiO64V3AyZKWj4ij2vdVzMysmU5fY3mO1N/VGFIX1UcX5n0XQNLKpAGxIHUNsgLpzlxIXT0cVnjP4fQFlc/mvNfn14fmsxkzM+ugTgeWTSPiqIh4MCJeIAWZxqBEq+Xn7ekbf+TYiJgUEePo61RtJ6Vxo+ehbxCduyJiXD6TOTanjcjLMjOzDupoYIlZu8aen77BnR7Nz+8tzL+nyfQSpP5xVs3TrfJB6vbczMw6qNutwr5JGlENoHGxvdj1+pQW0+VuvavmMzOzNuvafSy5hVhjDJLLgR82ZrV6S2E6BpCv1efvKWmCpAmTJw/GITPMzHpTVwKLpM+RxpaehzQ07zYRMT3PLu7li4MsLVaYnjyAfE1FxNiIWDsi1l522VmaYZuZ2RzqeGCRtBtpONB5SAPZbJEv5DfcXJhevcn086ThXu/L063yQRqJzczMOqjTN0h+HjiZFFQuAj4RaRjNonNIA9mMAL4u6SpgE/rGzD4r0jChSDqbNELhGpJ2Bi4ldecOqfPEc9r4dcysojHf/mu3iwDAxGO26nYRhoVOn7EcWvjMLYCXJUXhMSYiHqLv2st6pNETx+XXjzLzfSyH0teabBxpZLl18+vDy3fpm5lZ+w3KTigj4nukMZtvIw2Z+jRwJrB+cfyPPL1+nvd0znsbsIfvujcz646OVoVFxJgB5D2FvibI/eV7iNTdi5mZDQKD8ozFzMx6lwOLmZnVyoHFzMxq5cBiZma1cmAxM7NaObCYmVmtHFjMzKxWDixmZlYrBxYzM6uVA4uZmdXKgcXMzGrlwGJmZrVyYDEzs1o5sJiZWa0cWMzMrFYOLGZmVisHFjMzq5UDi5mZ1cqBxczMauXAYmZmtXJgMTOzWjmwmJlZrRxYzMysVg4sZmZWKwcWMzOr1RwHFkn/I2lbSW+qs0BmZtbbKgUWSb+SdGLh9Y7Av4Fzgf9IWr9N5TMzsx5T9YxlC+Cqwusjgd8BbwIuzq/NzMwqB5blgIcBJL0VWA34YURMAsYCa7WneGZm1muqBpZngFF5elNgUkTcnl8LmLfugpmZWW+ar2K+vwFHSBoF7A/8vjBvTWBizeUyM7MeVfWM5RvAdcCXSNdaDinM+wRwUc3lMjOzHlXpjCUinge+0GLeB2stkZmZ9TTfIGlmZrWqdMYi6QEgWsyeAUwBbgV+HhE31VQ2MzPrQVXPWP5ICkKLAdcDF+TnxYERwARgPeA6SZu3oZxmZtYjqrYKexK4B/hYRExrJEpaCPgL8BCpddj5wOGkmybNzGwYqnrG8jXg2GJQAYiIl4GfAntHxOvAScA76y2imZn1kqqBZUn6bpAsGwUsmqefB16f20KZmVnvqhpYLgB+KGk7SfMDSJpf0vbAD/N8SGcr99VfTDMz6xVVA8uXgPHAH4CXJT0HvEy6A/8a4Ms532PAQf0tSNJqkk6SdIekGZJC0mtN8k3M85o93lPKO1rSOEmTJb0s6VZJu1f8bmZmVqOqN0g+B2wj6R3A2sDywCRgQkTcUcj3hwqLWxPYYw7K2pSk5UlBb8VC8ruAkyUtHxFH1fVZZmY2ewO6QTIi7oiIMyLiB/n5jtm/axaPAkcDHwduqJD/8xGh0uOWwvzD6QsqnwVWIDWFBjhU0ug5KKOZmc2hqs2NAZC0OvBmYMHyvIi4sMoyIuJG4Ma8vG8O5POblGceYMf88q6IGJfTjwXOJt1jsz1w7Nx8jpmZVVf1zvu3k3bUbyd1k18WtK/r/B9LGgu8CFwLHBkR1+Z5qwJL5Ol7Cu8pTnusGDOzDqp6xvIrYH5gO+BO4NW2lWhWy+TnJYGPAptK2jQirgJGFvJNaTG9XJvLZ2ZmBVUDy1rAThFxwWxz1udEUhf9twMLka6l7EWq3joC2IjmZ0+U0pv2cSZpT2BPgNGjfRnGzKwuVS/e30eT6yrtFBHHRMT4iJgSEU8AXwVeyrPXyc+TC29ZvDC9WGG6mKe4/LERsXZErL3sssvWVm4zs+FuIAN9HSTpLe0sTEO+KF8W9J19zMjP95Hu9gdYvZC3OP2vektnZmb9qVoV9n1Sk97/SJoIPFfOEBHvr7IgSSPou+A+opDeuF7yArC5pJ2BX5KaJC9GqgpbJOcZnz9zhqSzSVVaa+T3XArsl/NNB86p9hXNzKwOVQPL7flRh/8HXF5Km5e+KqvPkwLXDvlR9iLw7cLrQ4GtSIFvXCnv4RHx8NwW2MzMqqt65/3n212QkmtJZyhbAG8BliIFnsuBIyLi7kLZJklan3RWtTmpQ8y7geMj4pQOl9vMbNgb0A2SdYiIK2jdmqvosPyossyHgJ3nuFBmZlabloFF0g9JR/2P5Ol+RcT+tZbMzMx6Un9nLJ8Cfgs8QrrW0WrMe/I8BxYzM2sdWCJilcL0mI6UxszMel6l+1gk7SppmRbzlpa0a73FMjOzXlX1BsnTSB0+NrNKnm9mZlY5sPTXimsZZu700czMhrH+WoVtA2xTSPqupHK/WwsCHySPr2JmZtZfq7DlgHcWXq9KGpK46FXgEuB7NZfLzMx6VH+twk4CTgKQdDnw5Yj4T6cKZmZmvalqly4bt7sgZmY2NFTu0kXSYqRrLqvTfMx73yBpZmaVx7xfFbgGWJjUdf1kYOn8/mdJY6I4sJiZWeXmxj8FJgCjSE2PtyQNF7wLMBXYsS2lMzOznlO1Kuz9wB7AK/n1/BHxOnBmHqDrOGD9NpTPzMx6TNUzlgWBKRExA3gGeFNh3u3Au+sumJmZ9aaqgeUeYOU8/S/gS5IWzMMM7w481o7CmZlZ76laFXYW8B7gN8B3gYtJ3bjMyMvYrR2FMzOz3lP1PpZjC9PXSVoT+CipiuyyiLi9TeUzM7MeM0dDE0fEw8BYACU7RsTZtZbMzMx6UtXxWJaVpFLaQpK+CtwLnNmOwpmZWe9pGVgkLSxprKSXgEnAs5K+meftBUwEjicFlo3aX1QzM+sF/VWFHQJ8DjgVuJXUKuwgSesB2wGXAQdGhLvMNzOzN/QXWLYDjoiIoxoJkq4ELgROjYg92l04MzPrPf1dY1kZuLKU1nh9RnuKY2Zmva6/wDKCNJBXUeP1i+0pjpmZ9brZNTf+X0mPF143WobtI+mJQnpExAH1Fs3MzHpRf4HlIWCDJukPAh8qpQXgwGJmZv0OTTymg+UwM7MhomonlGZmZpU4sJiZWa0cWMzMrFYOLGZmVqv++gobnQfyMjMzq6y/M5YHgLUAJF0m6X86UyQzM+tl/QWWl4GF8/RGwOJtL42ZmfW8/m6Q/BdwnKS/59flu/CLfOe9mZkB/QeWLwI/ArYh3Vm/CfBKi7y+897MzID+77z/D/BxAEkzgG0j4oZOFczMzHpT1THvVwFaVYOZmZm9oVJgiYgHJc0naUdSx5RLA88A/wTOjYjX2lhGMzPrIZVukJS0HDAB+B2wFfCW/HwWcKOkZat+oKTVJJ0k6Q5JMySFpKaBSdLukm6VNE3SZEnjJK3UJN/oPG+ypJfze3avWiYzM6tP1aqwY4FlgHWLY9xLWgf4Y57/2YrLWhOY7bDGkg4GjiwkLQDsDGwoaZ2ImJTzLQ+MB1Ys5H0XcLKk5YtDK5uZWftV7dJlS+CAYlAByK8PJJ29VPUocDSpYUDTxgCSVgYOyS+vB1agL3C9GTiskP1w+oLKZ3Pe6/PrQyWNHkDZzMxsLlUNLAsAL7SY9wIwf9UPjIgbI+I7EXEB6SbMZrYnDY0McGxETIqIccBdOW0nSfNImgfYMafdFRHj8pnMsTltRF6WmZl1SNXAch1wgKRFion59QF5fp3eW5i+p8n0EqSWaqvm6Vb5IHdLY2ZmnVH1Gss3gMuBhyVdAjwBLAdsDojU5UudRhamp7SYXq70nqr5AJC0J7AnwOjRri0zM6tLpTOWiLgFeCswFlgW2Iy0wz4ReGtE3FpzuVQhPQaQbxYRMTYi1o6ItZddtnKjNjMzm42qZyxExFPAt9tYlqLJheli55eLlfLMUzGfmZl1yGAd6OvmwvTqTaafJ3Xrf1+ebpUPUmeaZmbWIR0PLJJGSBopaSR9Lb9opElaADgHmJ5nfV3S8pJ2BtbIaWdFxIyImAGcndPWkLSzpFHAfjltel6WmZl1SDfOWP4fqXpqMrB+Tpu3kPbpiHgIOCLPW4/UT9m4/PpRZr6P5dCcRs4zCVg3vz48Ih6u/yuYmVkrg7UqjIj4HukO/dtI3fU/DZwJrN+46z7nm0QKUGfmPK/k9+zhu+7NzDpvthfvc9XUN4EL6mj9FRFX0Lo1VznvKcApFfI9ROruxczMumy2ZywR8QrwHWDJ9hfHzMx6XdWqsOuB97WzIGZmNjRUvY9lf+BMSa8CF5LuvJ/pxsOIeKnmspmZWQ+qGlgavQUfDxzXIs+8c18cMzPrdVUDyxdo0TWKmZlZUdWhiU9vcznMzGyIqNxXGICkt5Mu4q8EnBoRkyStBjwREa3GazEzs2GkUmCRtChwKmnQrOn5fReR7nI/GniIdK+LmZkNc1WbGx9Lurt9E1LPwcUbHC8Etqi5XGZm1qOqVoVtB+wTEZdLKrf+ehBYud5imZlZr6p6xrIQqR+uZhYDXq+nOGZm1uuqBpYbgV1bzNseGF9PcczMrNdVrQo7GLhU0qWk8U0C2FLS10mB5UNtKp+ZmfWYqmPeX026cL8A8HPSxfvDgbcAm0bEjW0roZmZ9ZSBjHl/DfBBSQsBSwHPuX8wMzMrm5OBvqaR7mV5ueaymJnZEFA5sEjaUtJ4UmCZBEyTNF7SVm0rnZmZ9ZxKgUXSXsBfgKnAPsCn8vNU4Pw838zMrPI1loOAsRHx5VL6iZJOJI0w+ataS2ZmZj2palXYMsC5Leb9EVi6nuKYmVmvqxpYLgc2bDFvQ+CqeopjZma9rmVVWO4iv+F44GRJywDnAU8CywGfAD4K7NHOQpqZWe/o7xrL7cw8aqSAvfIjmLmH44vw0MRmZkb/gWXjjpXCzMyGjJaBJSKu7GRBzMxsaBjQ0MQAkuYD5i+nu3sXMzOD6jdILiHpF5IeJ915/0KTh5mZWeUzltNJzYpPAu4FXm1XgczMrLdVDSybAHtFxO/aWRgzM+t9VW+QfAjwNRQzM5utqoFlf+BgSaPbWRgzM+t9larCIuJCSZsC90qaCDzXJM/7ay6bmZn1oEqBRdKPgX2BG/HFezMz60fVi/d7AN+JiO+3szBmZtb7ql5jeQm4qZ0FMTOzoaFqYDkO2FOSZpvTzMyGtapVYSOBdYG7JV3BrBfvIyIOqLNgZmbWm6oGlu2B14ARwGZN5gfgwGJmZpWbG6/S7oKYmdnQUPUaS8dJ2k1StHicV8q7u6RbJU2TNFnSOEkrdavsZmbDWdX7WL4yuzwR8Yu5L87ASToYOLKQtACwM7ChpHUiYlI3ymVmNlxVvcby837mNYYvbldgeTAixjSbIWll4JD88npgW2BT4DfAm4HDgC+1qVxmZtZEpaqwiJin/ACWBj4N3Aq8vZ2F7Mf2pAYFAMdGxKSIGAfcldN2kjRoq/vMzIaiOd7pRsRzEXE2cCLwq/qKNIs3SXpa0quS7pF0hKQF8rz3FvLd02R6CcAND8zMOqiOo/kHgLVrWE4rI0hnRyOAtwLfBf6c540s5JvSYnq5NpbNzMxK5iqwSFoB+AYpuNTtv8DuwBhgYWBj4Ik8b3NJGwGtegIopkfTDNKekiZImjB58uRaCmxmZtVbhU1m1h30/MBiwDRgu5rLRURcA1xTSLpC0nHA0fn1OkAxIixemF6sMN00akTEWGAswNprr900+JiZ2cBVbRV2ArMGlmnAI8BFEfF0raUCJM0TETNKycUyzABuBj6TX68O3FKYBnie9pxNmZlZC1XvvD+szeVo5nxJlwDnAU8C65HGhGkYDzwKfJ90/eXrkq4CNgHWyHnOahKczMysjaqesXTDm0m9Kh/XZN6ZEXEtgKQjSDdIrgc8XsjzKOk+FjMz66CWgUXSZQNYTkTEJjWUp+gQUjXX2sCbSNVgdwGnAb8sfPD3JD0OfA14GzAVuBg40Hfdm5l1Xn9nLFWum6wArE+LlldzIyLOB86vmPcU4JS6y2BmZgPXMrBExKdazZM0mtRN/seAp4Cf1l80MzPrRQO6xiJpNeBAYBfSBfUDgV9FxMttKJuZmfWgqvexvAP4DvAp4GFgH+DUiHi1jWUzM7Me1O+d95LeJ+lc4DZgLWAP4PYLtOIAABNxSURBVK0RcaKDipmZNdNfq7C/AR8hBZWdIuKcjpXKzMx6Vn9VYZvn55WAEySd0N+CIsKdPZqZWb+B5fCOlcLMzIaM/pobO7CYmdmAeXRFMzOrlQOLmZnVyoHFzMxq5cBiZma1cmAxM7NaObCYmVmtHFjMzKxWDixmZlYrBxYzM6uVA4uZmdXKgcXMzGrlwGJmZrVyYDEzs1o5sJiZWa0cWMzMrFYOLGZmVisHFjMzq5UDi5mZ1cqBxczMauXAYmZmtXJgMTOzWjmwmJlZrRxYzMysVg4sZmZWKwcWMzOrlQOLmZnVyoHFzMxq5cBiZma1cmAxM7NaObCYmVmtHFjMzKxWDixmZlarIRNYJI2WNE7SZEkvS7pV0u7dLpeZ2XAzX7cLUAdJywPjgRULye8CTpa0fEQc1Z2SmZkNP0MisACH0xdUPgtcCpwHrAscKuk3EfFQtwpnw9OYb/+120UAYOIxW3W7CDbM9HxVmKR5gB3zy7siYlxETAKOzWkjgO27Ujgzs2Go5wMLsCqwRJ6+p5BenF6rc8UxMxvehkJgGVmYntJierkOlcXMbNgbCtdYVCE9Zpkp7QnsmV9OlXR33QUboJHAU10uw2DhddFnrteFflBTSbrP66LPYPmPrNwscSgElsmF6cUL04u1yANARIwFxrarUAMlaUJErN3tcgwGXhd9vC76eF30GezrYihUhd0HPJ+nVy+kF6f/1bnimJkNbz0fWCJiBnB2frmGpJ0ljQL2y2nTgXO6Ujgzs2FoKFSFARwKbEW6l2Vcad7hEfFw54s0YIOmWm4Q8Lro43XRx+uiz6BeF4qY5bp2T5I0Gvg+sDmwKHA3cHxEnNLVgpmZDTNDJrCYmdng0PPXWMzMbHBxYDEzs1oNlYv3Q4IkASsBuNNMMyuTtCDwDmAGcEdEvNrlIjXlM5bBZWlgInB/l8thg4ik5XJnq8OapFGSDpF0SLfL0m6Svibpa6W0A0h3298ATACeGKxjTvni/SAiaRlSLwEREfN2uzztJmk1YB9gNeBR4NSIGF/K8wAwIyJW7UIRO0bSt4DPkO67+mVEnCbpi8APSJ2sTgEOi4jjuljMrpL0btLNzkP+/yFpBmm7ny+/3gX4Nal7qnJ3VZtHxKWdL2VrDiwdIumSCtlGABsyPP44bwFuYuZueACOjIjDCvlmMMTXRw4gv2LmPu0OIAUV6NuRBPDxiLiwg8XrKEmzq9ppVN+/RtouFmhzkbqivN1Luh5Yh1QFdilpW9iMVOt0SURs0a2yNuPA0iGNDaVKVob4jhRA0m+BTzeZFcDPIuIbOd9wCCzXkgalK5pB2mlMB+4g1auPAP4aER/vbAk7J//e/Wn8h4b0/6RJYHkRWBD4YkScmtP2IN0o+WxELNO1wjYx7Ottu0CzeQwX65N2EhcDawMbAH8nrYN9JQ2n4aTfTloXh5LO4I4g/TeDtCN5L9CoSx+0HQ/WKIAXgStLj5vo+49cCVzVldJ11+8L02fl54W7UZD++IylQyQ9ROpy5kMRcU2LPCOBJxnCR2INkl4G5gfeFBFP5DSRqoT2IO1cjiDtbIf0+sjVP/MCS0TEVElLAM+S1sFSETFF0qKk6yyvRcT8XSxuW+UDiv1I28YlwP9GxL153nC7xhLAGTlpO1KP7ctHxOScZyngaeDhiGjafX23+Iylc64lHW2t30+e4RTln87P0xoJkewJnEJaV0O+9U/2bH6eDyAiGr11ExGNAesaR+ovdrBcHRcR3wHeCVxE6p7p35KOzM1shxsBuwGfo+9a5DqF+Zvk5zs7WKZKfB9L55wEPEZq/dTKS8DhnSlO190DrAB8nFLHoRHxxXz28oVuFKwL7iUN3PRO4J85rXwdpTEMxGOdKlS35DOUrSRtDfwM+A6wC3BqVwvWWWe0SF+yMP3N/PyXNpdlwFwVZl0h6WBSVdc9wDsjYnqTPKcAn2eIV31I2hv4GPDHiDi5RZ5jgP2BUyLii50sXzdJWgA4kPTdF2CIX7QfiFxlCjA1Il7vamFKHFisK/IOo3H09VSrP4aklQEi4sFOlW0wkrQqqdfuxxp17MOJpDGkI/RFACLi890sj/XPgWUQGC43AZrZ3OuF/YUDyyAwHO7VGIhe+ON0itdFH0n3k/4nw3pd9ML+woFlEOiFDaWTvD76eF308bpIemE9uLmxmZnVys2NB4crGV73sJjZnLuK1OXPoOXA0mGS3gxsD6wFLEcKKA8B/5K0YkT0d5/LcHEVDrQNXhd9Bv0OtUN2B06W9I+I2GS2ubvA11g6SNKBpC5KRrTIMp3UNfoxnSvV4CVpfmAngIj4dZeL03WSRsPwGARO0pLA9Ih4sZD2XtIQC/dHxISuFa4DJPXXQ8dqwOmkA44NSPvx8f3k7zgHlg6R9AWg6c1vJQHsHhGnt7dEg19hfJo3xqUYqiTtAHyXvrFpTgZ+VLy/pzxGx1AkaRFSR4uNbuDHkY7QT2fm3rD/DHxqsN0YWJcKvaGrMD8G2zbhwNIhkm4B3gVcDxxLuuN8CmkDWYzUZcd+pO7Tb42ItbpU1EFjuAx8Jmkj4DL6BnFq/CkvA7ZtHLX3QmuguZU7oTywkBTAucAnS1kD+FpEnNCpsnVSIbC06vF8UA8f4MDSIZJeInVJsUJEPNkiz3LAJGBaRAy6rrDrVGFAp4b5GIR/nDpJuhT4cH45hdTT8SKkncc/gS0iYtowCSx3AGsAr9A3Ds38pB3ow8AfSUFmJWB8RGzQpaK2VSGwvETqZ/D5wuzlgb3o6wGciBhUfQy6uXHnTM3P/V1sa8yb2k+eoWK+io/hYE3STuKoiFgSWIZULRbAB4Hz8/Wm4WAV0vf+VESsTbrG1jiL2yUi9iMN4QxpHJuh6iOkWo1FSFWAD0TE4TmAnNjIVEgbVHzG0iGSxpH+EAHcRV9VGKQusVcnHakBnBkRn+14ITtIUqNu/Ebg5RbZRpAHBBviR+mN0QEXL12s3pXUo69I3ch/lKG/Lhrj9CwcEa/k7vJfIv1vFslnbguQtpmhPjbNfKTq8YNJAeYaYG/SCcGgHpfGgaVDJK1EGpPlTbS+KCfShdsPRMQjnSpbN0i6nRRIW47hPlwGPstdlawMjImIh0vzPkff+DSDsj69TpIeJv1HVoyISTmtPEzvssATpM5Ll+taYTtE0gqk67I7Aq8BfyMNqzBotwVXhXVI3mG8j1Rf2rhoX3xMIY1fvfZQDypZY+CzD/STZ7gc9dySn3cuz4iIM+gbUXM4uCM/F5vbLkbfQFcA787PD3SkRF0WEY9HxKeBjYG7mXWsnkFnuNRhDwqRhuDdS9KXgFVJgzuJ1PLpvhhep4/HABfQ/8Bnz5P+TEPdn0hnb1tLOj4iXirOjIjT88BnhzL0bxD8IXA5heuMxerBbBvStnFJB8vVdRFxpaT3ANuShlAYtFwVZmZmtXJVmJmZ1cqBxczMauXAMgxJOkxSFB6TJF0g6V3dLttQIunHkibWtKw/SLpiNnlOz7/n35vMW0jSC3n+bnWUqclnz3X/XZI2Km2bz0m6XtK2c7Cs5fK2PqbFZ6w5t+W15hxYhq/nSS2yPgDsS7qP5u+Slu5qqWxuTQU2ljSqlP6xNn/ukcBuNS5vZ9K2+RngaeBcSR8a4DKWIzV4GFNKvzkv+765LKO14MAyfL0WEdflx1nArqQ/4hazeZ8NbneTdpifKqXvBJzfrg+NiPsi4vYaF3lb3jYvJA0z8SywSx0Ljogpedmtbsy1ueTAYg235ueViomS9pB0h6RXJD0oaf/yGyV9SNLlkqZKel7SFZLWKsx/j6R/SHpJ0rOSfls8opY0JldN7CTpNElTJD0iaZc8f39Jj0maLOkHkuYpvPcwSU9JWlfSBEkvS7pa0iq5KuS8XK67JH2Yktl9v0YVj6TNJN0m6cW8/HeU8i0p6cw8/3FJ32m2kiWNlnSWpGfy+rhY0ttKeVaSdGH+LhMl7dFsWf04mzzcQF7eYsCWwFktyvRVSf/N6+BeSV8vzNs4/zbl77uUpFcl7V5cTwP9rlXk5tf3Utg2Ja0g6VRJ9+f1dI+k7yl3fZOrv/6ds1/eqFrL82apCsuv95F0dN7OnpR0gtJd/sXvtFHeDqZJulHS+/P2d9hAv9dQ5sBiDaPz8xs3nUn6FvBL4DxSVcovgSMlfbWQZyPgH6SxZD5Hujv4n8CKef6ywBXAwqRqjf8FNiRVu5W74/gB8Dipk8F/AmdI+gnwfuALwM+A/YEdSu9bmHRz6U9J/SqNBn4D/A64GtiOdL/MOZLe6NyzyvcrrJsfAUfl5S8H/F5SsefZ00hdruwL7Enq62mn4kKUqhmvBt4GfCl/j0WASyUtlPOI1CX8mqTu4vcD9qH/G0nLfgesrzx+C/AJ0hH/leWMkr4I/B/pbObjwDnATyR9O2e5kvSblNf5J/Lzn5oVoMp3rSofSLyZmW+IHAk8Q1o/W5B+n8/n70Iuc+OG073pq/btzzdId/3vkpe3F2ndN8qxInAhqTeI7YFfAb8FBvR9hoWI8GOYPYDDgKfo6+hxVeDvpP6HFsh5FifV1x9aeu8RpB6Y582vrwUmkO+JavJZxwDPkfrBaqS9n3Qn+afz6zH59WmFPIuTgtV/G5+V028Azi59lwA2LKR9JacdUkh7e0776AC/3+mkbjTeWsizbV7W/+TX78ivdyzkWZS045tYSDuSdL1g6ULaUqTrXXvn11vmZa1byLNyLsMVs/ldTwcm5OlbgW/l6QtJQXnRvOzdcvo8pIB7Wmk5v8hlWjC/Pg74TynPxcAFzT676ndt8R02ymV8N2nbXJa0k38OeFs/75uPdOAyDZg/pzU699yoxWesWUgL4KpSvvOA6wqvf0T63yxUSNshv/ewbv+vB9PDZyzD1zKkHfd0UjXDWsB2EfFKnv8B0hHmOZLmazxIY4SMAt6sNCjTusAZkf9lTbwfuCQiGh1uEhE3ABNJo98V/aOQZwqpR4IrY+bBnO4lnw0VvEo6wynmIZe1nNZ472y/X+G9EyPiv4XXd+bnRp518vMb1zAiYiopWBdtmtOmFD7vBeAmYO2c5/3AExFxfWFZD+Y8A3EWsFM+c9iU5tVgbyYdoZ9TSj+bFHjfWXj9Nknvhjf6cPtwTm+lynftzy2kbfNJ0lnJbhFxd2Omkn0l3anUceV00tnDAvSdfQ9U+U7+O5l5O1gH+HvMfG2mbdetepkDy/D1POmPsh7plH9+4Ez1Xb8YmZ/voC8ATSd1twGpvnspUpc0j/fzOSuQOgwsewIot0B7rvT61RZpC5bSXoiIGaU8My0vIhppjfdW+X79lau4rOVzGcoXg8vj7owkVRVOLz02Lnze8k3e12xZs3MW8F7gIODRiLiuSZ4V8nP592m8bvw+1wIP5bJDqqp8jXRE30qV79qfnUjb5ydJDRJOk/Smwvx9gZ+QquK2IQXkvfO88vZR1ey2teVJBztviIhpDI9hLgbEfYUNX69F37jh1+ejvl+TWhOdTarGgXTtoVlguJvUb9UM+nZQzTxOuiZRNoqBH4XXqcr3q2oSsJikhUrBpfy9nyEd4R7ZZBkvFJbVbH0tR+vhBWYREQ9IugH4OqkKp5nGAUH58xoNK57JywpJvycFioPy898i4gVaq/Jd+3NHpFZmEyTdSjp7+C7w5Tz/U8A5EfFGIwlJ7R6fZRKpau4NSt36D+p+u7rBZyzWMI509H5Afn0taUf2poiY0OTxQqTOAa8Hdi1dyC66Htg8t0wCQNI6pOsqV7fry1Qw2+83gGXdmJ+3biRIWhTYrJTvH6TrMXc0+by7C8saJWndwrJGk84+BuonwF9IBwzNPAI8xqxNk3cg9bb970LaWcBbJH2M1PiiaQuzgirftZKIuA84GdhNaZRVSBfMXyllLfcOXT6znFs3ApuVGh9s3SrzcOYzFgPeOCo9GvitpE0i4h+5CeVxklYGriIdiKwObBwRjVZB3wYuBf4maSzwIun6xYSIuIA0jsSXgYsl/YB0dHcMaaf1x859w5lFxHMVv1+VZd0h6Xzgl5IWJ50JfIs0QFXRsaQWR5dJ+j/ShfNRpB311RHxO9KF9ltJ134OIF2MPoKBV4UREb8Hft/P/Bl5HfxK0tOkayIbkn6vg3I1TyPvTZLuJbW+e5nUM3V/qnzXgfgh8EVSq8Lv5rJ+TdL1pPt2dgZWK73noVzWz0l6HpheOEufEz8jVbf9RdJPSVVj3yb9zkO91+kB8RmLFZ1NaoW1P0BE/JDUdPajpCawvyP9gd+4UB4RV5GOzBcmnfWcTdp5PJLnTybVq0/L7z8hv3+zwnWPrqjy/QZgN9LF35+RBub6B6Wj+oh4inRN6z+kptGXkHaYSwC35TxBOgq+kzR65M+An5POsGoXEScBXyM1H76A1Jz6GxFxTJPsZ5OqPf8Spa79myx3tt91gOV8kLR9fSU3GjmC9Ht9Lz+/mr9H8T3TSMHofaRm0zcyFyLiUWArUtXhuaQg9wVgXvpGgzXcbb6Z2RyTtAHpQOTDEXH57PIPFw4sZmYV5ercf5Eu5L+NVC33NLBWqWXisOZrLGZm1S1AamU3itS67RJgPweVmfmMxczMauWL92ZmVisHFjMzq5UDi5mZ1cqBxczMauXAYmZmtXJgMTOzWv1/UvgxK5fg7pUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranges = ['0-1', '1-2', '2-3', '3-4', '4-5']\n",
    "ad = pd.DataFrame(avg_rating).melt()\n",
    "ad['ratingrange'] = pd.cut(ad['value'], bins=[0,1,2,3,4,5], labels=ranges, right=True)\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "ax = ad.groupby(['ratingrange'])['ratingrange'].count().plot.bar()\n",
    "ax.set_ylabel('Number of Ratings')\n",
    "ax.set_xlabel('Recommended Movie Rating')\n",
    "ax.set_title('Ratings - Recommended Movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Diversity: Checking for the long tail\n",
    "Want to recommend some \"unpopular\" movies such that users view movies in the long tail that they otherwise would not be exposed to\n",
    "- Generate recommendations for random  users\n",
    "- Merge in count of number of reviews for the recommended movies\n",
    "- Take the minimum count (extent of the long tail)\n",
    "- Average minimum counts across random users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def global_diversity(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2, \n",
    "                     recommendation_system, recommendation_system_input1, recommendation_system_input2):\n",
    "\n",
    "    length = len(rand_user)\n",
    "    min_cnt = []\n",
    "\n",
    "    # loop through random users\n",
    "    for u in range(length):\n",
    "        # getting recommended movies\n",
    "        recommendation = recommendation_system(rand_user[u], df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "        # getting the min rating cnt of the movies recommended\n",
    "        min_rating_cnt = recommendation[:top_n]['cnt'].min()\n",
    "        \n",
    "        # keep track\n",
    "        min_cnt.append(min_rating_cnt)\n",
    "\n",
    "    # take average of minimum counts \n",
    "    avg_min_cnt = np.mean(min_cnt)\n",
    "    \n",
    "    return avg_min_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# random sample of n users \n",
    "rand_user = random.sample(list_user, n)  \n",
    "\n",
    "avg_min_cnt = global_diversity(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2, \n",
    "                               recommendation_system, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "print(f\"Average of the minimum count of ratings for {n} user's top {top_n} recommendations (long tail):{np.round(avg_min_cnt,2)}\",\n",
    "      file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
